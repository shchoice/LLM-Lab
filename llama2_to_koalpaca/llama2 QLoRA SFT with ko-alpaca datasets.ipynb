{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d63012c-c15f-45f1-a451-9aaef25a089c",
   "metadata": {},
   "source": [
    "# LLaMA-2 모델의 한국어 능력을 위한 QLoRA SFT (With KoALPACA 데이터셋 및 Standford Alpaca 코드 기반)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e92b42-dff7-4d3b-8fd3-9137114abb92",
   "metadata": {},
   "source": [
    "## 0. 순서\n",
    "1. [개요](#1.-개요)\n",
    "2. [Set Arguments](#2.-Set-Arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c5a5c2-71fa-4790-a30c-525d31ff27ed",
   "metadata": {},
   "source": [
    "## 1. 개요\n",
    "* 모델명 :[meta-llama/Llama-2-7b-hf](https://huggingface.co/meta-llama/Llama-2-7b-hf)\n",
    "* 데이터셋\n",
    "    * 한국어 Alpaca Dataset : [ko_alpaca_data.json](https://github.com/Beomi/KoAlpaca/blob/main/ko_alpaca_data.json)\n",
    "    * 네이버 지식인 베스트 데이터 : [KoAlpaca_v1.1.json](https://raw.githubusercontent.com/Beomi/KoAlpaca/main/KoAlpaca_v1.1.jsonl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7cef433-4d78-41a5-81f5-8ec9337609f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)  # 열 너비 제한 해제\n",
    "pd.set_option('display.max_rows', 100)       # 표시되는 최대 행 수 설정\n",
    "import logging\n",
    "import json\n",
    "import random\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, Sequence\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from peft import (\n",
    "    prepare_model_for_kbit_training,\n",
    "    LoraConfig,\n",
    "    get_peft_model\n",
    ")\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c0d0be-bb79-46b9-af40-926fa52f3ab6",
   "metadata": {},
   "source": [
    "## 2. Set Arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f640f056-5d93-4653-b251-f02605972980",
   "metadata": {},
   "source": [
    "### 2.1 base 관련 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c2e018e-5120-40b1-ac41-013efc6cdc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = '/workspace/llama2-KoAlpaca-Finetuning'\n",
    "PARENT_DIR = os.path.dirname(BASE_PATH)\n",
    "RANDOM_SEED = 777\n",
    "HUGGINGFACE_TOKEN = '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'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3557b1-1740-4396-b353-5601a3fa1c33",
   "metadata": {},
   "source": [
    "### 2.2 Dataset 관련 파라미터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c085a7-16bc-4ed3-b354-9ead7189b507",
   "metadata": {},
   "source": [
    "!wget https://github.com/Beomi/KoAlpaca/blob/main/ko_alpaca_data.json\n",
    "!wget https://github.com/Beomi/KoAlpaca/blob/main/KoAlpaca_v1.1.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20118a58-064c-4c7e-a38e-e4b43f818f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join(BASE_PATH, 'datas')\n",
    "DATASET_KO_ALPACA_V_1_0_PATH = os.path.join(DATA_DIR, 'ko_alpaca_data.json')\n",
    "DATASET_KO_ALPACA_V_1_1_PATH = os.path.join(DATA_DIR, 'KoAlpaca_v1.1.jsonl')\n",
    "DATASET_KO_ALPACA_MERGE_V_1_0_and_V_1_1_PATH = os.path.join(DATA_DIR, 'final_ko_alpaca_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5db9eee-8b8c-494d-b6f6-49b2482db6cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/llama2-KoAlpaca-Finetuning/datas/final_ko_alpaca_data.json'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET_KO_ALPACA_MERGE_V_1_0_and_V_1_1_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cb395d-5fc7-4afb-9a7d-3e55c4844bce",
   "metadata": {},
   "source": [
    "### 2.3 Model 관련 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1905dae-7148-43e8-ac4b-b2ea00e00dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Arguments\n",
    "MODEL_NAME_OR_PATH = 'meta-llama/Llama-2-7b-hf'\n",
    "RESUME_FROM_CHECKPOINT = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be30a758-75b0-46cf-8abc-d2166d231e32",
   "metadata": {},
   "source": [
    "### 2.4 Trainer(Transformers) 관련 파라미터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74eb559-7a87-41f1-8641-5e17fbd2b5cf",
   "metadata": {},
   "source": [
    "* 훈련 결과 산출물 관련 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ada611e-2f4f-4826-87b3-6b13cfe545a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPT_NAME=\"expt-2epochs\"                            # Experiment name\n",
    "CACHE_DIR=os.path.join(PARENT_DIR, \".cache\")        # Cache directory\n",
    "OUTPUT_DIR=os.path.join(DATA_DIR, \"output\", EXPT_NAME)    # Output directory\n",
    "LOGGING_DIR=os.path.join(DATA_DIR, \"logging\", EXPT_NAME)  # Logging directory\n",
    "REPORT_TO=['mlflow','tensorboard']                  # Report the results and logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccbb9e0-cd48-465c-bfa0-f802dd9a1baa",
   "metadata": {},
   "source": [
    "* 훈련 관련 파라미터 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb9c8da6-507a-415c-8b00-b170951f3cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRAIN_EPOCHS=3                                  # Training epochs\n",
    "TRAIN_BATCH_SIZE=8                                  # Training batch size\n",
    "EVAL_BATCH_SIZE=8                                   # Evaluation batch size\n",
    "EVALUATION_STRATEGY=\"steps\"                         # Evaluation strategy\n",
    "EVAL_STEPS=500                                      # Evaluation steps\n",
    "SAVE_STEPS=500                                      # Save steps\n",
    "LOGGING_STEPS=200                                   # Logging steps\n",
    "LEARNING_RATE=3e-4                                  # Learning rate\n",
    "LR_SCHEDULER_TYPE=\"cosine\"                          # LR scheduler type\n",
    "OPTIM=\"paged_adamw_8bit\"                            # Optimizer type\n",
    "WARMUP_RATIO=0.1                                    # Warmup ratio\n",
    "WARMUP_STEPS=None\n",
    "WEIGHT_DECAY=0.05                                   # Weight decay\n",
    "GRADIENT_ACCUMULATION_STEPS=4                       # Gradient accumulation steps\n",
    "LOAD_BEST_MODEL_AT_END=True                         # Load best model at end\n",
    "FP16=True                                           # Use fp16\n",
    "EARLY_STOPPING_PATIENCE=10                          # Early stopping patience"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bee027-4040-4ebb-90e6-3f3fc82f2abb",
   "metadata": {},
   "source": [
    "* 분산 관련 옵션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e5826ee-bd70-4ff5-aaf7-cd0ae1b7a509",
   "metadata": {},
   "outputs": [],
   "source": [
    "DDP = False\n",
    "DDP_FIND_UNUSED_PARAMETERS=False                    # DDP find unused parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3910e3fd-367a-4059-8f1b-6d7b75be18a7",
   "metadata": {},
   "source": [
    "### 2.5 양자화 관련 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "567eb1b8-8e2e-4f6d-afef-92036b86b21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_IN_4BIT=True                                   # Enable 4-bit quantization\n",
    "BNB_4BIT_QUANT_TYPE=\"nf4\"                           # BNB 4-bit quantization type\n",
    "BNB_4BIT_COMPUTE_DTYPE=torch.bfloat16               # BNB 4-bit compute dtype\n",
    "BNB_4BIT_USE_DOUBLE_QUANT=True                      # BNB 4-bit use double quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adf1d16-d2c3-462a-9c8d-fe91a4b86aef",
   "metadata": {},
   "source": [
    "### 2.6 LoRA 관련 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38583777-2400-4b58-b20c-73247dc2bc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "R=8                                                 # Lora attention dimension\n",
    "LORA_ALPHA=16                                       # Lora alpha parameter\n",
    "LORA_DROPOUT=0.05                                   # Lora dropout probability\n",
    "FAN_IN_FAN_OUT=False                                # Lora fan in fan out\n",
    "BIAS=\"none\"                                         # Lora bias type\n",
    "TARGET_MODULES=[\"q_proj\", \"v_proj\"]                 # Lora target modules\n",
    "INFERENCE_MODE=False                                # Inference mode\n",
    "TASK_TYPE=\"CAUSAL_LM\"                               # Task type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d64c107-298a-44f0-beb5-cc957e3ddb57",
   "metadata": {},
   "source": [
    "### 2.7 Tokenizer 관련 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4315f9d-a23c-4831-a2db-e3aa356a7e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENIZER_NAME_OR_PATH = 'meta-llama/Llama-2-7b-hf' # TODO. 46592 tokens (Sentencepiece BPE. Added Korean vocab and merges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db556941-b8b6-4384-b382-25d5a630bcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH=1024                                     # Max sequence length for tokenizer\n",
    "TRUNCATION=True                                     # Enable/disable truncation\n",
    "RETURN_OVERFLOWING_TOKENS=True                      # Return overflowing tokens info\n",
    "RETURN_LENGTH=True                                  # Return length of encoded inputs\n",
    "PADDING=True                                        # Enable padding to max sequence length\n",
    "PADDING_SIDE=\"right\"                                # The side on which the model should have padding appliedㅠ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9433f82e-d33d-498c-93e9-b65e1817a5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS_TOKEN = \"<s>\"\n",
    "EOS_TOKEN = \"</s>\"\n",
    "UNK_TOKEN = \"<unk>\"\n",
    "IGNORE_INDEX = -100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e277100f-2c49-43d6-9d04-e634a394f216",
   "metadata": {},
   "source": [
    "### 2.8 MLFlow관련 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4ad2454-939b-4868-bc75-76245769b1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLFLOW_TRACKING_URI=\"http://127.0.0.1:5000\"         # URI of MLFlow installed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28243782-7836-47d8-ae3d-205b95e623b0",
   "metadata": {},
   "source": [
    "### 2.9 PROMPT(Simple) 관련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b264bbc1-7d4d-42cd-9a75-dc5b70914e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = {\n",
    "    \"prompt_input\": \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\n",
    "아래는 작업을 설명하는 명령어와 추가적 맥락을 제공하는 입력이 짝을 이루는 예제입니다. 요청을 적절히 완료하는 응답을 작성하세요.\\n\\n\n",
    "### Instruction(명령어):\\n{instruction}\\n\\n\n",
    "### Input(입력):\\n{input}\\n\\n\n",
    "### Response(응답):\\n\"\"\",\n",
    "    \n",
    "    \"prompt_no_input\": \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\n",
    "아래는 작업을 설명하는 명령어입니다. 명령어에 따른 요청을 적절히 완료하는 응답을 작성하세요.\\n\\n\n",
    "### Instruction(명령어):\\n{instruction}\\n\\n\n",
    "### Response(응답):\\n\"\"\",\n",
    "    \n",
    "    \"response_split\": \"### Response(응답):\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6752501d-6496-4145-ab6e-cc8cdb5cf2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os.path as os\n",
    "from typing import Union\n",
    "\n",
    "\n",
    "class Prompter:\n",
    "    __slots__ = (\"template\")\n",
    "\n",
    "    def __init__(self, instruct_template):\n",
    "        self.template = instruct_template\n",
    "\n",
    "    def generate_prompt(self,\n",
    "                        instruction: str,\n",
    "                        input: Union[None, str] = None,\n",
    "                        label: Union[None, str] = None,\n",
    "                       ) -> str:\n",
    "        if input:\n",
    "            res = self.template[\"prompt_input\"].format(\n",
    "                instruction=instruction, input=input\n",
    "            )\n",
    "        else:\n",
    "            res = self.template[\"prompt_no_input\"].format(\n",
    "                instruction=instruction\n",
    "            )\n",
    "        if label:\n",
    "            res = f\"{res}{label}\"\n",
    "\n",
    "        return res\n",
    "\n",
    "    def get_response(self, output: str) -> str:\n",
    "        return output.split(self.template[\"response_split\"])[1].strip()\n",
    "        \n",
    "prompter = Prompter(PROMPT_TEMPLATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3822d1e-8084-4e5c-b9dc-26c80bc21f80",
   "metadata": {},
   "source": [
    "## 3. 데이터 셋 살펴보기 및 하나로 합치기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b9813a-9c5d-46af-93a4-b047e6e9833b",
   "metadata": {},
   "source": [
    "### 3.1 한국어 Aplaca 데이터셋(ko_alpaca_data.json) 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa849e2f-667d-440f-8ed7-83574dfdac52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>건강을 유지하기 위한 세 가지 팁을 알려주세요.</td>\n",
       "      <td></td>\n",
       "      <td>세 가지 팁은 아침식사를 꼭 챙기며, 충분한 수면을 취하고, 적극적으로 운동을 하는 것입니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>세 가지 기본 색은 무엇인가요?</td>\n",
       "      <td></td>\n",
       "      <td>기본 색은 빨강, 파랑, 노랑입니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>원자의 구조를 설명하세요.</td>\n",
       "      <td></td>\n",
       "      <td>원자는 양성자, 중성자, 전자로 구성되어 있으며, 양성자와 중성자는 원자핵 안에 있고 전자는 주변에 있습니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>대기 오염을 어떻게 줄일 수 있나요?</td>\n",
       "      <td></td>\n",
       "      <td>대기 오염을 줄이기 위해 자동차 대신 대중교통을 이용하고, 미세먼지 배출량을 줄이기 위해 차량 정기 검사를 받아야 합니다. 또한 에너지 절약을 위해 전기를 아끼고, 나무를 심어 대기 오염을 줄일 수 있습니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>어려운 결정을 내려야 했던 때를 설명하세요.</td>\n",
       "      <td></td>\n",
       "      <td>제가 어려운 결정을 내려야 했던 때는 대학원 졸업 후 직장을 찾아야 했던 때입니다. 다양한 선택지가 있었지만 나의 관심사와 비전에 가장 부합하는 경력을 뽑는데 어려움이 있었습니다. 이 때 여러 사람들의 조언과 현재 상황에 대한 깊은 고민 끝에 적절한 선택을 내리게 되었습니다.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  instruction input  \\\n",
       "0  건강을 유지하기 위한 세 가지 팁을 알려주세요.         \n",
       "1           세 가지 기본 색은 무엇인가요?         \n",
       "2              원자의 구조를 설명하세요.         \n",
       "3        대기 오염을 어떻게 줄일 수 있나요?         \n",
       "4    어려운 결정을 내려야 했던 때를 설명하세요.         \n",
       "\n",
       "                                                                                                                                                       output  \n",
       "0                                                                                                        세 가지 팁은 아침식사를 꼭 챙기며, 충분한 수면을 취하고, 적극적으로 운동을 하는 것입니다.  \n",
       "1                                                                                                                                        기본 색은 빨강, 파랑, 노랑입니다.  \n",
       "2                                                                                               원자는 양성자, 중성자, 전자로 구성되어 있으며, 양성자와 중성자는 원자핵 안에 있고 전자는 주변에 있습니다.  \n",
       "3                                        대기 오염을 줄이기 위해 자동차 대신 대중교통을 이용하고, 미세먼지 배출량을 줄이기 위해 차량 정기 검사를 받아야 합니다. 또한 에너지 절약을 위해 전기를 아끼고, 나무를 심어 대기 오염을 줄일 수 있습니다.  \n",
       "4  제가 어려운 결정을 내려야 했던 때는 대학원 졸업 후 직장을 찾아야 했던 때입니다. 다양한 선택지가 있었지만 나의 관심사와 비전에 가장 부합하는 경력을 뽑는데 어려움이 있었습니다. 이 때 여러 사람들의 조언과 현재 상황에 대한 깊은 고민 끝에 적절한 선택을 내리게 되었습니다.  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(DATASET_KO_ALPACA_V_1_0_PATH, 'r', encoding='utf-8') as file:\n",
    "    ko_alpaca_data_v_1_0 = json.load(file)\n",
    "\n",
    "df_ko_alpaca_data_v_1_0 = pd.DataFrame(ko_alpaca_data_v_1_0)\n",
    "df_ko_alpaca_data_v_1_0.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bd7d24-5ce8-4fd7-9ecb-fae318556449",
   "metadata": {},
   "source": [
    "### 3.2 네이버 지식인 베스트 데이터(KoAlpaca_v1.1.json) 살펴보기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb9eab36-5bb9-4edb-989a-747ff374f041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>양파는 어떤 식물 부위인가요? 그리고 고구마는 뿌리인가요?</td>\n",
       "      <td>양파는 잎이 아닌 식물의 줄기 부분입니다. 고구마는 식물의 뿌리 부분입니다. \\n\\n식물의 부위의 구분에 대해 궁금해하는 분이라면 분명 이 질문에 대한 답을 찾고 있을 것입니다. 양파는 잎이 아닌 줄기 부분입니다. 고구마는 다른 질문과 답변에서 언급된 것과 같이 뿌리 부분입니다. 따라서, 양파는 식물의 줄기 부분이 되고, 고구마는 식물의 뿌리 부분입니다.\\n\\n 덧붙이는 답변: 고구마 줄기도 볶아먹을 수 있나요? \\n\\n고구마 줄기도 식용으로 볶아먹을 수 있습니다. 하지만 줄기 뿐만 아니라, 잎, 씨, 뿌리까지 모든 부위가 식용으로 활용되기도 합니다. 다만, 한국에서는 일반적으로 뿌리 부분인 고구마를 주로 먹습니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>스웨터의 유래는 어디에서 시작되었나요?</td>\n",
       "      <td>스웨터의 유래는 14세기경 북유럽항구지역에서 어망을 짜던 기술을 의복에 활용하면서 시작되었습니다. 노동자들의 방한복에서 시작된 스웨터는 여가생활과 스포츠의 붐에 힘입어 대중화되었습니다. 이후, 겨울철 이너웨어의 대명사가 되었습니다. 스웨터는 짜서(Knit) 만든 옷을 말하며, 어부들의 방한복으로 짜여졌던 스웨터 중에서도 스코틀랜드 해안지방의 여인들은 바다로 나가는 남편이나 연인, 자식들에게 무사히 돌아올 것을 기원하며 로프나 닻 무늬를 정성껏 짜넣었다고 합니다. 그 실용성과 정성이 오늘에까지 이어지고 있습니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>토성의 고리가 빛의 띠로 보이는 이유는 무엇인가요?  \\n\\n토성의 고리는 얼음과 같은 여러 물질로 이루어져 있다고 알고 있는데, 카시니가 찍은 사진에서 마치 빛의 띠 처럼 보이는 이유가 무엇인가요? 물질의 공전 속도가 빠르기 때문에 카메라로 담았을 때 빛의 궤적으로 보이는 건가요? 또한, 야간에 빠르게 움직이는 자동차를 장노출로 찍었을 때 빛의 궤적이 생기는 것과 같은 원리일까요? 그리고 빛의 궤적이 생기는 것은 우주라는 어두운 환경 특성 때문이라고 생각됩니다. 이게 맞을까요?</td>\n",
       "      <td>토성의 고리가 미세한 입자들로 이루어져 있기 때문에, 입자들의 밀도 차이 때문에 카시니 탐사선에서 찍은 고해상도 사진에서 빛의 띠가 보이는 것입니다.  \\n\\n실제로는 토성의 고리 입자들의 운동이 장노출 사진에서 잔상이 생기는 이유와 관련이 없습니다. 물체의 운동은 토성의 고리가 매끄럽게 보이는 이유와 상관이 없습니다. \\n\\n밀도 차이로 생긴 미세한 입자들의 밀도는 연속적인 것이 아니며 광학계의 분해능으로 인해 고해상도 사진에서 입자 간격이 잘 보이지 않습니다. 따라서, 토성의 고리가 빛의 띠로 보이는 것은 고리 입자밀도의 차이 때문입니다. \\n\\n이렇게 입자들의 밀도 차이가 빛의 띠처럼 보이는 것은, 마치 축구장에서 앉아 조각판처럼 보이는 것과 같은 현상으로 이해할 수 있습니다. 마찬가지로, 먼 광활지에서 숲은 보이고 나무는 안 보이며, 이것은 발생하는 현상과 유사합니다.\\n\\n더 자세한 사항을 알고 싶다면 우주선이 고리를 아주 가까이 찍어 볼 필요가 있습니다. 이것은 훨씬 상세한 데이터를 얻기 위해서는 더욱 다양한 탐사가 필요합니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>화장품 OEM과 화장품 ODM의 차이점은 무엇인가요?\\n화장품 자체 제조 브랜드 런칭을 위해 OEM과 ODM용어에 대해 혼란스러움을 느끼고 있습니다. 두 용어의 차이점이 무엇인지 알고 싶습니다.</td>\n",
       "      <td>화장품 제조업체는 대체로 OEM과 ODM을 통해 제품을 만듭니다. OEM은 브랜드에서 제품을 주문하였을 때, 반제품이나 완제품으로 납품받는 방식입니다. 반면 ODM은 자체 개발 능력을 갖춘 제조원이 유통까지 담당하여 상품을 공급하는 방식입니다. ODM은 직접 연구 개발을 통해 제품을 만들어주는 점에서 OEM과 차이가 있습니다. 대표적인 OEM/ODM 기업에는 코스맥스, 오울코리아, 한국콜마 등이 있습니다. 최근에는 OEM과 ODM의 경계가 허물어지고 있어 브랜딩부터 용기와 케이스 디자인까지 전반적인 제품 제조를 담당하는 기업도 많습니다. 이를 바탕으로, OEM은 브랜드에서 주문한 제품을 납품받고, ODM은 직접 개발하여 유통까지 책임지는 차이점이 있습니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'사이보그'는 언제 처음 등장한 말이며, 그 의미와 종류에는 어떤 것이 있는지 알고 싶습니다.</td>\n",
       "      <td>'사이보그'는 1960년에 처음 등장한 말로, 기계와 유기체가 합성되어 생겨난 새로운 개념을 나타냅니다. 주로 공상과학영화에서 등장하며, 1985년 페미니스트인 도나 해러웨이가 발표한 '사이보그를 위한 선언문'으로 인해 사이보그는 성차별 사회를 극복하는 사회정치적 상징으로 더욱 주목받게 되었습니다. 사이보그는 생물체와 기술적 개입이 결합된 다양한 종류가 있으며, 이제는 인공장기를 받은 사람, 예방접종을 받은 사람, 또는 사람과 기계가 결합된 베리칩과 같은 기술적 개입을 받은 사람들까지 우리 주변에서 만날 수 있습니다. \\n\\n또한, 지구 위치 파악 기능이나 신체 건강 상태를 감지하는 센서 등을 추가적으로 부착하면서 사이보그의 구조와 기능이 더욱 다양해지고 있습니다. 이러한 발전은 사이보그의 대중화를 가속화시키고 있으나, 범죄나 인권 침해 등의 문제가 발생할 가능성도 존재합니다.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                      instruction  \\\n",
       "0                                                                                                                                                                                                                                                양파는 어떤 식물 부위인가요? 그리고 고구마는 뿌리인가요?   \n",
       "1                                                                                                                                                                                                                                                           스웨터의 유래는 어디에서 시작되었나요?   \n",
       "2  토성의 고리가 빛의 띠로 보이는 이유는 무엇인가요?  \\n\\n토성의 고리는 얼음과 같은 여러 물질로 이루어져 있다고 알고 있는데, 카시니가 찍은 사진에서 마치 빛의 띠 처럼 보이는 이유가 무엇인가요? 물질의 공전 속도가 빠르기 때문에 카메라로 담았을 때 빛의 궤적으로 보이는 건가요? 또한, 야간에 빠르게 움직이는 자동차를 장노출로 찍었을 때 빛의 궤적이 생기는 것과 같은 원리일까요? 그리고 빛의 궤적이 생기는 것은 우주라는 어두운 환경 특성 때문이라고 생각됩니다. 이게 맞을까요?   \n",
       "3                                                                                                                                                                    화장품 OEM과 화장품 ODM의 차이점은 무엇인가요?\\n화장품 자체 제조 브랜드 런칭을 위해 OEM과 ODM용어에 대해 혼란스러움을 느끼고 있습니다. 두 용어의 차이점이 무엇인지 알고 싶습니다.   \n",
       "4                                                                                                                                                                                                                            '사이보그'는 언제 처음 등장한 말이며, 그 의미와 종류에는 어떤 것이 있는지 알고 싶습니다.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 output  \n",
       "0                                                                                                                                                                                          양파는 잎이 아닌 식물의 줄기 부분입니다. 고구마는 식물의 뿌리 부분입니다. \\n\\n식물의 부위의 구분에 대해 궁금해하는 분이라면 분명 이 질문에 대한 답을 찾고 있을 것입니다. 양파는 잎이 아닌 줄기 부분입니다. 고구마는 다른 질문과 답변에서 언급된 것과 같이 뿌리 부분입니다. 따라서, 양파는 식물의 줄기 부분이 되고, 고구마는 식물의 뿌리 부분입니다.\\n\\n 덧붙이는 답변: 고구마 줄기도 볶아먹을 수 있나요? \\n\\n고구마 줄기도 식용으로 볶아먹을 수 있습니다. 하지만 줄기 뿐만 아니라, 잎, 씨, 뿌리까지 모든 부위가 식용으로 활용되기도 합니다. 다만, 한국에서는 일반적으로 뿌리 부분인 고구마를 주로 먹습니다.  \n",
       "1                                                                                                                                                                                                                                                      스웨터의 유래는 14세기경 북유럽항구지역에서 어망을 짜던 기술을 의복에 활용하면서 시작되었습니다. 노동자들의 방한복에서 시작된 스웨터는 여가생활과 스포츠의 붐에 힘입어 대중화되었습니다. 이후, 겨울철 이너웨어의 대명사가 되었습니다. 스웨터는 짜서(Knit) 만든 옷을 말하며, 어부들의 방한복으로 짜여졌던 스웨터 중에서도 스코틀랜드 해안지방의 여인들은 바다로 나가는 남편이나 연인, 자식들에게 무사히 돌아올 것을 기원하며 로프나 닻 무늬를 정성껏 짜넣었다고 합니다. 그 실용성과 정성이 오늘에까지 이어지고 있습니다.  \n",
       "2  토성의 고리가 미세한 입자들로 이루어져 있기 때문에, 입자들의 밀도 차이 때문에 카시니 탐사선에서 찍은 고해상도 사진에서 빛의 띠가 보이는 것입니다.  \\n\\n실제로는 토성의 고리 입자들의 운동이 장노출 사진에서 잔상이 생기는 이유와 관련이 없습니다. 물체의 운동은 토성의 고리가 매끄럽게 보이는 이유와 상관이 없습니다. \\n\\n밀도 차이로 생긴 미세한 입자들의 밀도는 연속적인 것이 아니며 광학계의 분해능으로 인해 고해상도 사진에서 입자 간격이 잘 보이지 않습니다. 따라서, 토성의 고리가 빛의 띠로 보이는 것은 고리 입자밀도의 차이 때문입니다. \\n\\n이렇게 입자들의 밀도 차이가 빛의 띠처럼 보이는 것은, 마치 축구장에서 앉아 조각판처럼 보이는 것과 같은 현상으로 이해할 수 있습니다. 마찬가지로, 먼 광활지에서 숲은 보이고 나무는 안 보이며, 이것은 발생하는 현상과 유사합니다.\\n\\n더 자세한 사항을 알고 싶다면 우주선이 고리를 아주 가까이 찍어 볼 필요가 있습니다. 이것은 훨씬 상세한 데이터를 얻기 위해서는 더욱 다양한 탐사가 필요합니다.  \n",
       "3                                                                                                                                                                   화장품 제조업체는 대체로 OEM과 ODM을 통해 제품을 만듭니다. OEM은 브랜드에서 제품을 주문하였을 때, 반제품이나 완제품으로 납품받는 방식입니다. 반면 ODM은 자체 개발 능력을 갖춘 제조원이 유통까지 담당하여 상품을 공급하는 방식입니다. ODM은 직접 연구 개발을 통해 제품을 만들어주는 점에서 OEM과 차이가 있습니다. 대표적인 OEM/ODM 기업에는 코스맥스, 오울코리아, 한국콜마 등이 있습니다. 최근에는 OEM과 ODM의 경계가 허물어지고 있어 브랜딩부터 용기와 케이스 디자인까지 전반적인 제품 제조를 담당하는 기업도 많습니다. 이를 바탕으로, OEM은 브랜드에서 주문한 제품을 납품받고, ODM은 직접 개발하여 유통까지 책임지는 차이점이 있습니다.  \n",
       "4                                                                                              '사이보그'는 1960년에 처음 등장한 말로, 기계와 유기체가 합성되어 생겨난 새로운 개념을 나타냅니다. 주로 공상과학영화에서 등장하며, 1985년 페미니스트인 도나 해러웨이가 발표한 '사이보그를 위한 선언문'으로 인해 사이보그는 성차별 사회를 극복하는 사회정치적 상징으로 더욱 주목받게 되었습니다. 사이보그는 생물체와 기술적 개입이 결합된 다양한 종류가 있으며, 이제는 인공장기를 받은 사람, 예방접종을 받은 사람, 또는 사람과 기계가 결합된 베리칩과 같은 기술적 개입을 받은 사람들까지 우리 주변에서 만날 수 있습니다. \\n\\n또한, 지구 위치 파악 기능이나 신체 건강 상태를 감지하는 센서 등을 추가적으로 부착하면서 사이보그의 구조와 기능이 더욱 다양해지고 있습니다. 이러한 발전은 사이보그의 대중화를 가속화시키고 있으나, 범죄나 인권 침해 등의 문제가 발생할 가능성도 존재합니다.  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ko_alpaca_data_v_1_1 = []\n",
    "with open(DATASET_KO_ALPACA_V_1_1_PATH, 'r',encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        data = json.loads(line)\n",
    "         # 'instruction'과 'output' 키만 추출\n",
    "        if 'instruction' in data and 'output' in data:\n",
    "            ko_alpaca_data_v_1_1.append({'instruction': data['instruction'], 'output': data['output']})\n",
    "\n",
    "df_ko_alpaca_data_v_1_1 = pd.DataFrame(ko_alpaca_data_v_1_1)\n",
    "df_ko_alpaca_data_v_1_1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15d9bb0-8d03-4a71-9024-81054a892f19",
   "metadata": {},
   "source": [
    "### 3.3 2개의 데이터 합치고, 랜덤 셔플링 하고, json 파일로 저장하기\n",
    "* 데이터를 데이터 프레임 자료형으로 보여주기 위해 데이터프레임을 임시적으로 사용하였고\n",
    "* **실제 학습 코드에서는 `json 파일을 사용`**할 예정이라 데이터프레임을 json 파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "adab2a83-db84-4d3f-b1b4-0cd9d62e4dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>이메일에서 스팸을 탐지하기 위한 기계 학습 알고리즘을 만드세요.</td>\n",
       "      <td></td>\n",
       "      <td>이메일 스팸 탐지 알고리즘을 위한 몇 가지 인기있는 기계 학습 모델에는 Support vector machine (SVM)와 Naive Bayes classifier가 있습니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>고기 요리 시 맛술을 사용하는 이유와 대체재는 무엇인가요? 어떤 음식에 맛술을 사용하나요?</td>\n",
       "      <td></td>\n",
       "      <td>안녕하세요! 고기 요리 시 맛술을 사용하는 이유는 냄새와 맛의 개선입니다. 근육 안에 있는 균일한 살코기와 지방에 의해 맛이 가려진 고기를 숙성시켜 고소하고 부드러운 맛을 냄새를 덜어주는 기능을합니다. 또한 연유를 돕는 기능도 합니다. 맛술 대신 청주나 소주를 사용할 수 있지만, 이 경우 마이너스 영향을 주는 것보다는 과일 등을 갈아넣어 연유작용과 단맛을 살릴 수 있습니다. 흔히 널리 사용되는 음식에는 갈비, 쇠불고기, 돼지불고기, 닭갈비 등이 있습니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>대화를 시작하기 위해 트윗을 작성합니다.</td>\n",
       "      <td></td>\n",
       "      <td>'안녕하세요! 오늘 날씨가 참 좋네요!'  (트윗 예시)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>저녁과 밤의 구분 기준은 무엇인가요? 저녁 8시가 맞나요? 밤 8시가 맞나요?</td>\n",
       "      <td></td>\n",
       "      <td>저녁과 밤을 구분하는 기준은 명확히 정의되어 있지 않습니다. '저녁'은 해가 지고 밤이 되기까지의 사이, 혹은 식사를 할 때 사용하며, '밤'은 해가 진 후부터 날이 새기 전까지의 시간을 의미합니다. 따라서, 저녁과 밤의 구분은 개인적인 해석에 따라 다를 수 있고 명확한 기준은 없습니다. \\n\\n일반적으로 저녁시간은 대개 저녁식사를 하는 시간을 의미하며, 보통은 오후 6시부터 9시까지를 말합니다. 따라서, 8시가 저녁의 일부가 될 수도 있습니다. 밤 시간의 시작과 끝 역시 관련 기준이 명확하지 않습니다. 하지만 대체적으로 일몰 후부터 일출 전까지의 시간을 밤으로 보는 경우가 많습니다. 따라서 밤 8시 역시 밤에 속하는 시간대에 포함될 수도 있습니다. \\n\\n하지만 저녁과 밤을 명확히 구분 짓는 것은 쉽지 않은 일이고 사람마다 다를 수 있을 것입니다. 따라서, 구분할 때는 개인의 판단과 환경적인 조건을 고려하는 것이 좋습니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>이 문장의 시작 부분에 전환 단어를 삽입하세요.</td>\n",
       "      <td>그는 오랫동안 수색한 끝에 보물을 찾았습니다.</td>\n",
       "      <td>그러나, 그는 오랫동안 수색한 끝에 보물을 찾았습니다.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          instruction  \\\n",
       "0                 이메일에서 스팸을 탐지하기 위한 기계 학습 알고리즘을 만드세요.   \n",
       "1  고기 요리 시 맛술을 사용하는 이유와 대체재는 무엇인가요? 어떤 음식에 맛술을 사용하나요?   \n",
       "2                              대화를 시작하기 위해 트윗을 작성합니다.   \n",
       "3         저녁과 밤의 구분 기준은 무엇인가요? 저녁 8시가 맞나요? 밤 8시가 맞나요?   \n",
       "4                          이 문장의 시작 부분에 전환 단어를 삽입하세요.   \n",
       "\n",
       "                       input  \\\n",
       "0                              \n",
       "1                              \n",
       "2                              \n",
       "3                              \n",
       "4  그는 오랫동안 수색한 끝에 보물을 찾았습니다.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                output  \n",
       "0                                                                                                                                                                                                                                                                                                                                                                                  이메일 스팸 탐지 알고리즘을 위한 몇 가지 인기있는 기계 학습 모델에는 Support vector machine (SVM)와 Naive Bayes classifier가 있습니다.  \n",
       "1                                                                                                                                                                                                                     안녕하세요! 고기 요리 시 맛술을 사용하는 이유는 냄새와 맛의 개선입니다. 근육 안에 있는 균일한 살코기와 지방에 의해 맛이 가려진 고기를 숙성시켜 고소하고 부드러운 맛을 냄새를 덜어주는 기능을합니다. 또한 연유를 돕는 기능도 합니다. 맛술 대신 청주나 소주를 사용할 수 있지만, 이 경우 마이너스 영향을 주는 것보다는 과일 등을 갈아넣어 연유작용과 단맛을 살릴 수 있습니다. 흔히 널리 사용되는 음식에는 갈비, 쇠불고기, 돼지불고기, 닭갈비 등이 있습니다.  \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                      '안녕하세요! 오늘 날씨가 참 좋네요!'  (트윗 예시)  \n",
       "3  저녁과 밤을 구분하는 기준은 명확히 정의되어 있지 않습니다. '저녁'은 해가 지고 밤이 되기까지의 사이, 혹은 식사를 할 때 사용하며, '밤'은 해가 진 후부터 날이 새기 전까지의 시간을 의미합니다. 따라서, 저녁과 밤의 구분은 개인적인 해석에 따라 다를 수 있고 명확한 기준은 없습니다. \\n\\n일반적으로 저녁시간은 대개 저녁식사를 하는 시간을 의미하며, 보통은 오후 6시부터 9시까지를 말합니다. 따라서, 8시가 저녁의 일부가 될 수도 있습니다. 밤 시간의 시작과 끝 역시 관련 기준이 명확하지 않습니다. 하지만 대체적으로 일몰 후부터 일출 전까지의 시간을 밤으로 보는 경우가 많습니다. 따라서 밤 8시 역시 밤에 속하는 시간대에 포함될 수도 있습니다. \\n\\n하지만 저녁과 밤을 명확히 구분 짓는 것은 쉽지 않은 일이고 사람마다 다를 수 있을 것입니다. 따라서, 구분할 때는 개인의 판단과 환경적인 조건을 고려하는 것이 좋습니다.  \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                       그러나, 그는 오랫동안 수색한 끝에 보물을 찾았습니다.  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ko_alpaca_combined = pd.concat([df_ko_alpaca_data_v_1_0, df_ko_alpaca_data_v_1_1])\n",
    "df_ko_alpaca_combined_shuffled = df_ko_alpaca_combined.sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True)\n",
    "df_ko_alpaca_combined_shuffled['input'] = df_ko_alpaca_combined_shuffled['input'].fillna('')\n",
    "df_ko_alpaca_combined_shuffled.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9495a8f-52a0-4c30-9abf-92b98e6adfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ko_alpaca_combined_shuffled.to_json(DATASET_KO_ALPACA_MERGE_V_1_0_and_V_1_1_PATH, orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b256f976-448f-450c-bb22-bf7c4417e6fd",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7400daf3-de68-49a4-9372-4cc843cfa98d",
   "metadata": {},
   "source": [
    "## 4. 모델 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ea1d3e-5e65-41f7-9b02-dc1f4c2c2d78",
   "metadata": {},
   "source": [
    "### 4.1 모델 학습을 위한 기본 확인사항 내용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c92bd74-84b5-43fa-b774-dc5131c6be54",
   "metadata": {},
   "source": [
    "* 모델 파라미터 정보 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5799f0ae-94c1-4978-9d91-2809ef6e15b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    all_params = sum(p.numel() for p in model.parameters())\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_params} || trainable%: {100 * trainable_params / all_params}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ee04df-662c-4d94-95d3-457ed8dfeffb",
   "metadata": {},
   "source": [
    "* GPU 분산학습 설정 사용 유무 점검"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e89cd1d-f5ee-423e-9304-436a7707d8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_device_map():\n",
    "    print(f\"num_gpus: {torch.cuda.device_count()}\")\n",
    "    world_size = int(os.environ.get(\"WORLD_SIZE\", torch.cuda.device_count()))\n",
    "    print(f\"world_size: {world_size}\")\n",
    "    DDP = world_size != 1\n",
    "    if DDP:\n",
    "        device_map = {\"\": int(os.environ.get(\"LOCAL_RANK\") or 0)}\n",
    "        GRADIENT_ACCUMULATION_STEPS = TRAIN_BATCH_SIZE // world_size\n",
    "        if GRADIENT_ACCUMULATION_STEPS == 0:\n",
    "            GRADIENT_ACCUMULATION_STEPS = 1\n",
    "        print(f\"ddp is on - gradient_accumulation_steps: {GRADIENT_ACCUMULATION_STEPS}\")\n",
    "    else:\n",
    "        device_map = \"auto\"\n",
    "        print(\"ddp is off\")\n",
    "\n",
    "    return device_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534f9822-3bbf-4db6-8dfb-c02c72fcdb98",
   "metadata": {},
   "source": [
    "### 4.2 모델 Load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17ef2a4-9991-41c8-b6e2-a1ec6f28ed1b",
   "metadata": {},
   "source": [
    "* 양자화 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3c2733e-0304-43f7-8f03-6082378be7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=LOAD_IN_4BIT,\n",
    "    bnb_4bit_use_double_quant=BNB_4BIT_USE_DOUBLE_QUANT,\n",
    "    bnb_4bit_quant_type=BNB_4BIT_QUANT_TYPE,\n",
    "    bnb_4bit_compute_dtype=BNB_4BIT_COMPUTE_DTYPE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3832b1ef-b4b2-4774-b5a5-960683ab51fe",
   "metadata": {},
   "source": [
    "* 모델 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c591e526-5a4f-4793-98c7-5dd92d0ddc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_gpus: 1\n",
      "world_size: 1\n",
      "ddp is off\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "085ef26280d945d894bc0fb90ff369a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 262410240 || all params: 3500412928 || trainable%: 7.496550989769399\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME_OR_PATH,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=get_device_map(),\n",
    "    cache_dir=CACHE_DIR,\n",
    "    token=HUGGINGFACE_TOKEN\n",
    ")\n",
    "\n",
    "print_trainable_parameters(model)\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cf2b4c-1cc3-4353-b7e5-1c51d8df8332",
   "metadata": {},
   "source": [
    "* Lora 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e893e921-a033-41c6-9a9c-925fb97582d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = LoraConfig(\n",
    "    r=R,\n",
    "    lora_alpha=LORA_ALPHA,\n",
    "    target_modules=TARGET_MODULES,\n",
    "    fan_in_fan_out=FAN_IN_FAN_OUT,\n",
    "    lora_dropout=LORA_DROPOUT,\n",
    "    inference_mode=INFERENCE_MODE,\n",
    "    bias=BIAS,\n",
    "    task_type=TASK_TYPE\n",
    ")\n",
    "model = get_peft_model(model, config)\n",
    "\n",
    "if not DDP and torch.cuda.device_count() > 1:\n",
    "    model.is_parallelizable = True\n",
    "    model.model_parallel = True\n",
    "    print(\"not ddp - trying its own DataParallelism\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "560bc405-9dfd-4277-9d13-f076333e0fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "peft.peft_model.PeftModelForCausalLM"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48ba3577-53b7-4b75-959e-19418319ab72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 4,194,304 || all params: 6,742,609,920 || trainable%: 0.06220594176090199\n"
     ]
    }
   ],
   "source": [
    "model.print_trainable_parameters() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f3d7d82e-b795-4696-be87-41851c5c6835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 4194304 || all params: 3504607232 || trainable%: 0.11967971650867153\n"
     ]
    }
   ],
   "source": [
    "print_trainable_parameters(model) # ?? TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593fcfae-73ea-4bb6-8c45-dc0aa94db08b",
   "metadata": {},
   "source": [
    "### 4.3 Tokenizer 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba358cfb-a148-4fe3-b7de-5c74b9e36128",
   "metadata": {},
   "source": [
    "* 모델 tokenizer 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "71a66218-070b-45dc-b980-cac52203307c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check bos_token, pad_token, eos_tokenm unk_token : <s>, </s>, </s>, <unk>\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    TOKENIZER_NAME_OR_PATH,\n",
    "    cache_dir=CACHE_DIR,\n",
    "    model_max_length = MAX_LENGTH,\n",
    "    padding_side=PADDING_SIDE,\n",
    "    token = HUGGINGFACE_TOKEN,\n",
    "    add_eos_token=True,\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "print(f'Check bos_token, pad_token, eos_tokenm unk_token : {tokenizer.bos_token}, {tokenizer.pad_token}, {tokenizer.eos_token}, {tokenizer.unk_token}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488da641-41e0-4e4c-b500-d984c0fd6361",
   "metadata": {},
   "source": [
    "* 모델의 tokenizer 가 올바르게 작동하는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e8f44bf9-e1e4-41f6-9903-98639d1b2680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Text: ['<s>', 'Hello', ',', 'world', '!', '</s>']\n"
     ]
    }
   ],
   "source": [
    "sample_en_sentence = \"Hello, world!\"\n",
    "tokenized_output = tokenizer(sample_en_sentence, add_special_tokens=True)\n",
    "print(\"Tokenized Text:\", [tokenizer.decode([x]) for x in tokenized_output[\"input_ids\"]])\n",
    "# Tokenized Text: ['<s>', 'Hello', ',', 'world', '!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "db2e8b26-a4cf-4fd3-b9ad-a02f37a8b206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Text: ['<s>', '', '안', '�', '�', '�', '하', '세', '요', '.', 'L', 'LM', '', '월', '드', '에', '', '오', '신', '�', '�', '�', '', '�', '�', '�', '영', '합', '니', '다', '.', '</s>']\n"
     ]
    }
   ],
   "source": [
    "sample_ko_sentence = \"안녕하세요. LLM 월드에 오신걸 환영합니다.\"\n",
    "tokenized_output = tokenizer(sample_ko_sentence, add_special_tokens=True)\n",
    "print(\"Tokenized Text:\", [tokenizer.decode([x]) for x in tokenized_output[\"input_ids\"]])\n",
    "# Tokenized Text: ['<s>', 'Hello', ',', 'world', '!']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171adfa3-71f2-4b9e-af77-a3018c20b7a7",
   "metadata": {},
   "source": [
    "* special tokeN 이 존재할 경우 추가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7f1131d0-897d-4ae5-89b8-51ab160aefb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smart_tokenizer_and_embedding_resize(\n",
    "    special_tokens_dict: Dict,\n",
    "    tokenizer: transformers.PreTrainedTokenizer,\n",
    "    model: transformers.PreTrainedModel,\n",
    "):\n",
    "    \"\"\"Resize tokenizer and embedding.\n",
    "\n",
    "    Note: This is the unoptimized version that may make your embedding size not be divisible by 64.\n",
    "    \"\"\"\n",
    "    print('smart_tokenizer_and_embedding_resize func running')\n",
    "    num_new_tokens = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "    if num_new_tokens > 0:\n",
    "        input_embeddings = model.get_input_embeddings().weight.data\n",
    "        output_embeddings = model.get_output_embeddings().weight.data\n",
    "\n",
    "        input_embeddings_avg = input_embeddings[:-num_new_tokens].mean(dim=0, keepdim=True)\n",
    "        output_embeddings_avg = output_embeddings[:-num_new_tokens].mean(dim=0, keepdim=True)\n",
    "\n",
    "        input_embeddings[-num_new_tokens:] = input_embeddings_avg\n",
    "        output_embeddings[-num_new_tokens:] = output_embeddings_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "765a3444-31a9-4380-937f-7a35098b64c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tokenizer.pad_token is None:\n",
    "    smart_tokenizer_and_embedding_resize(\n",
    "        special_tokens_dict=dict(pad_token=DEFAULT_PAD_TOKEN),\n",
    "        tokenizer=tokenizer,\n",
    "        model=model,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "be951bd3-9392-49fb-bd9c-fdd8dcbe74c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"llama\" in MODEL_NAME_OR_PATH:\n",
    "    tokenizer.add_special_tokens(\n",
    "        {\n",
    "            \"eos_token\": EOS_TOKEN,\n",
    "            \"bos_token\": BOS_TOKEN,\n",
    "            \"unk_token\": UNK_TOKEN,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a7de0e62-69dd-4abe-93f9-7a8e32c30778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ed8562-c548-4d91-945a-fddb8712e5e9",
   "metadata": {},
   "source": [
    "* 토크나저를 통한 데이터 처리 프로세스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eb79418e-dc83-4d81-8bb5-c52f81f12b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(\n",
    "    sources: Sequence[str],\n",
    "    targets: Sequence[str],\n",
    "    tokenizer: transformers.PreTrainedTokenizer,\n",
    ") -> Dict:\n",
    "    \"\"\"Preprocess the data by tokenizing.\"\"\"\n",
    "    examples = [s + t for s, t in zip(sources, targets)]\n",
    "    examples_tokenized, sources_tokenized = [_tokenize_fn(strings, tokenizer) for strings in (examples, sources)]\n",
    "    input_ids = examples_tokenized[\"input_ids\"]\n",
    "    labels = copy.deepcopy(input_ids)\n",
    "    for label, source_len in zip(labels, sources_tokenized[\"input_ids_lens\"]):\n",
    "        label[:source_len] = IGNORE_INDEX\n",
    "    return dict(input_ids=input_ids, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9de98e3a-a58c-4efc-9dcf-e20d67b58e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _tokenize_fn(strings: Sequence[str], tokenizer: transformers.PreTrainedTokenizer) -> Dict:\n",
    "    \"\"\"Tokenize a list of strings.\"\"\"\n",
    "    tokenized_list = [\n",
    "        tokenizer(\n",
    "            text,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=PADDING,\n",
    "            max_length=MAX_LENGTH,\n",
    "            truncation=True,\n",
    "        )\n",
    "        for text in strings\n",
    "    ]\n",
    "    input_ids = labels = [tokenized.input_ids[0] for tokenized in tokenized_list]\n",
    "    input_ids_lens = labels_lens = [\n",
    "        tokenized.input_ids.ne(tokenizer.pad_token_id).sum().item() for tokenized in tokenized_list\n",
    "    ]\n",
    "    return dict(\n",
    "        input_ids=input_ids,\n",
    "        labels=labels,\n",
    "        input_ids_lens=input_ids_lens,\n",
    "        labels_lens=labels_lens,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "30bc4a9d-40fa-466f-9eac-1c3fd0f3a92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupervisedDataset(Dataset):\n",
    "    \"\"\"Dataset for supervised fine-tuning.\"\"\"\n",
    "\n",
    "    def __init__(self, dataset: str, tokenizer: transformers.PreTrainedTokenizer):\n",
    "        super(SupervisedDataset, self).__init__()\n",
    "        logging.warning(\"Loading data...\")\n",
    "        list_data_dict = dataset\n",
    "\n",
    "        logging.warning(\"Formatting inputs...\")\n",
    "        prompt_input, prompt_no_input = PROMPT_TEMPLATE[\"prompt_input\"], PROMPT_TEMPLATE[\"prompt_no_input\"]\n",
    "        sources = [\n",
    "            prompt_input.format_map(example) if example.get(\"input\", \"\") != \"\" else prompt_no_input.format_map(example)\n",
    "            for example in list_data_dict\n",
    "        ]\n",
    "        targets = [f\"{example['output']}{tokenizer.eos_token}\" for example in list_data_dict]\n",
    "\n",
    "        logging.warning(\"Tokenizing inputs... This may take some time...\")\n",
    "        print(\"tokenizer\", tokenizer)\n",
    "        data_dict = preprocess(sources, targets, tokenizer)\n",
    "\n",
    "        self.input_ids = data_dict[\"input_ids\"]\n",
    "        self.labels = data_dict[\"labels\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, i) -> Dict[str, torch.Tensor]:\n",
    "        return dict(input_ids=self.input_ids[i], labels=self.labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e8adbb-13ad-4445-9f06-0d9a1113e05a",
   "metadata": {},
   "source": [
    "## 5. 데이터 로드 및 모델에 들어가기 위한 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2d90d5-37c6-4a9d-84ee-2c159c9ea9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATASET_KO_ALPACA_MERGE_V_1_0_and_V_1_1_PATH, 'r') as file:\n",
    "    dataset = json.load(file)\n",
    "\n",
    "train_dataset = SupervisedDataset(tokenizer=tokenizer, dataset=dataset)\n",
    "eval_dataset = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced3858d-d966-4883-9c21-5bb5f7b348cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataCollatorForSupervisedDataset(object):\n",
    "    \"\"\"Collate examples for supervised fine-tuning.\"\"\"\n",
    "\n",
    "    tokenizer: transformers.PreTrainedTokenizer\n",
    "\n",
    "    def __call__(self, instances: Sequence[Dict]) -> Dict[str, torch.Tensor]:\n",
    "        input_ids, labels = tuple([instance[key] for instance in instances] for key in (\"input_ids\", \"labels\"))\n",
    "        input_ids = torch.nn.utils.rnn.pad_sequence(\n",
    "            input_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id\n",
    "        )\n",
    "        labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=IGNORE_INDEX)\n",
    "        return dict(\n",
    "            input_ids=input_ids,\n",
    "            labels=labels,\n",
    "            attention_mask=input_ids.ne(self.tokenizer.pad_token_id),\n",
    "        )\n",
    "\n",
    "data_collator = DataCollatorForSupervisedDataset(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b161657-42dd-491a-9b5f-2169bcb0c94d",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "* 모델 tokenizer를 통해 사용할 데이터셋을 분석하여 입력 데이터의 길이 분포를 파악"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3c879844-fdcf-49c8-b9ee-9059af8c9684",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1069 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Length: 245.09052631578948\n",
      "Max Length: 2877\n",
      "Min Length: 2\n",
      "Median Length: 151\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 데이터 추출\n",
    "texts = [example['input'] + example['output'] for example in dataset]\n",
    "\n",
    "# 토큰 길이 계산\n",
    "token_lengths = [len(tokenizer.encode(text)) for text in texts]\n",
    "\n",
    "# 길이 분포 분석\n",
    "average_length = sum(token_lengths) / len(token_lengths)\n",
    "max_length = max(token_lengths)\n",
    "min_length = min(token_lengths)\n",
    "median_length = sorted(token_lengths)[len(token_lengths) // 2]\n",
    "\n",
    "print(f\"Average Length: {average_length}\")\n",
    "print(f\"Max Length: {max_length}\")\n",
    "print(f\"Min Length: {min_length}\")\n",
    "print(f\"Median Length: {median_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66891f7-7426-497a-a832-b07051151373",
   "metadata": {},
   "source": [
    "## 6. 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0d9a44-c40b-4b42-8049-5d735ffe98c1",
   "metadata": {},
   "source": [
    "### 6.1 Transformer Trainer를 사용하기 위한 argument 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee6b6df-c1de-4814-850b-b96c1e7fa08f",
   "metadata": {},
   "source": [
    "* WARMUP_STEPS 계산하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "919d9556-f151-41c3-947b-182de5d41364",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = len(train_dataset) / TRAIN_BATCH_SIZE\n",
    "total_steps = steps_per_epoch * NUM_TRAIN_EPOCHS\n",
    "WARMUP_STEPS = int(total_steps * WARMUP_RATIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "40db05db-4cf8-4da1-b5a7-d7bcffbc9d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    logging_dir=LOGGING_DIR,\n",
    "    report_to=REPORT_TO,\n",
    "\n",
    "    num_train_epochs=NUM_TRAIN_EPOCHS,\n",
    "    per_device_train_batch_size=TRAIN_BATCH_SIZE,\n",
    "    # per_device_eval_batch_size=EVAL_BATCH_SIZE,\n",
    "\n",
    "    # evaluation_strategy=EVALUATION_STRATEGY,\n",
    "    # eval_steps=EVAL_STEPS,\n",
    "    save_steps=SAVE_STEPS,\n",
    "    logging_steps=LOGGING_STEPS,\n",
    "\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    lr_scheduler_type=LR_SCHEDULER_TYPE,\n",
    "    optim=OPTIM,\n",
    "\n",
    "    warmup_ratio=WARMUP_RATIO,\n",
    "    warmup_steps=WARMUP_STEPS,\n",
    "\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "\n",
    "    gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
    "    # load_best_model_at_end=LOAD_BEST_MODEL_AT_END,\n",
    "    fp16=FP16,\n",
    "    ddp_find_unused_parameters=DDP_FIND_UNUSED_PARAMETERS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0fe0ba1f-afbd-4003-941d-aa5d7f9e4ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:accelerate.utils.other:Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f3a766-6eef-44d8-b713-9b4ad3728398",
   "metadata": {},
   "source": [
    "* chekcpoint를 통한 추가 학습 설정 여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "40f65bd5-5fab-4703-9056-30a16e4ae809",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RESUME_FROM_CHECKPOINT:\n",
    "    checkpoint_name = os.path.join(\n",
    "        resume_from_checkpoint, \"pytorch_model.bin\"\n",
    "    )  # All checkpoint\n",
    "\n",
    "    if not os.path.exists(checkpoint_name):\n",
    "        checkpoint_name = os.path.join(\n",
    "            resume_from_checkpoint, \"adapter_model.bin\"\n",
    "        )  # only LoRA model\n",
    "        resume_from_checkpoint = (\n",
    "            True\n",
    "        ) # kyujin: I will use this checkpoint\n",
    "\n",
    "    if os.path.exists(checkpoint_name):\n",
    "        print(f\"Restarting from {checkpoint_name}\")\n",
    "        adapters_weights = torch.load(checkpoint_name)\n",
    "        set_peft_model_state_dict(model, adapters_weights)\n",
    "\n",
    "    else:\n",
    "        print(f\"Checkpoint {checkpoint_name} not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d16e9f03-b22e-4b58-9304-76972d23b823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 4,194,304 || all params: 6,742,609,920 || trainable%: 0.06220594176090199\n"
     ]
    }
   ],
   "source": [
    "model.config.use_cache = False\n",
    "model.print_trainable_parameters() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ed12aa-e00d-455e-9a8e-02ec35f2d0df",
   "metadata": {},
   "source": [
    "### 6.2 학습하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbb3d96-e472-4430-b35e-d51c37a70563",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e15138d-965e-4fbb-8277-33849a9f31b0",
   "metadata": {},
   "source": [
    "### 6.3 학습한 모델 및 LoRA Adapter 저장 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d6ba70-1b15-4194-9f01-0d341a1293d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model\n",
    "trainer.save_state()\n",
    "model_path = os.path.join(output_dir, \"pytorch_model.bin\")\n",
    "torch.save({}, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbc92b9-9800-402e-b413-75f7672e7abc",
   "metadata": {},
   "source": [
    "### 6.4 LoRA Adapter merge\n",
    "* 훈련한 LoRA layer를 base model에 merge 하여 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c6c295-07fc-44ea-b90c-e2e5ddaebf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME_OR_PATH,\n",
    "    return_dict = True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=get_device_map(),\n",
    "    cache_dir=CACHE_DIR)\n",
    "\n",
    "final_model = PeftModel.from_pretrained(base_model, OUTPUT_DIR, get_device_map())\n",
    "model = model.merge_and_unload() # Merge!\n",
    "final_save_folder = '/workspace/output/custom_LLM_final'\n",
    "\n",
    "model.save_pretrained(final_save_folder)\n",
    "tokenizer.save_pretrained(final_save_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a688b91e-4464-48e6-947f-3a16a88a7924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd830e66-6a21-4215-b4be-8695e0fd7349",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
