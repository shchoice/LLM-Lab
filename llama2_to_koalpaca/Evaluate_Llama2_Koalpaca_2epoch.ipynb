{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47b1f051-d66d-4662-9abd-aed002d40348",
   "metadata": {},
   "source": [
    "# LLaMA2-7b 모델을 KoALPACA 모델로의 학습 후 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424e4efd-9f1f-4a99-8626-e3b0b9e46caf",
   "metadata": {},
   "source": [
    "## 1. 개요\n",
    "* 모델명 :[meta-llama/Llama-2-7b-hf](https://huggingface.co/meta-llama/Llama-2-7b-hf) 모델을 아래의 QLoRA로 SFT 한 모델\n",
    "* 데이터셋\n",
    "    * 한국어 Alpaca Dataset : [ko_alpaca_data.json](https://github.com/Beomi/KoAlpaca/blob/main/ko_alpaca_data.json)\n",
    "    * 네이버 지식인 베스트 데이터 : [KoAlpaca_v1.1.json](https://raw.githubusercontent.com/Beomi/KoAlpaca/main/KoAlpaca_v1.1.jsonl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3de0d054-a301-453b-afbf-60cba7f15e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from peft import (\n",
    "    prepare_model_for_kbit_training,\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    PeftModel,\n",
    ")\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    GenerationConfig,\n",
    ")\n",
    "\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab4473e-780e-409d-893f-94bc94c48db5",
   "metadata": {},
   "source": [
    "## 2. Set Arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e35093-bae0-42d2-814d-9dd45a43c21d",
   "metadata": {},
   "source": [
    "### 2.1 base 관련 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "657ba9bd-39ce-4f4f-bbfe-0a4ee52a690e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = '/workspace/llama2-KoAlpaca-Finetuning/output/checkpoint-2200'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a8c0fc9-b231-4ad7-b5b1-3f416c1d49fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = '/workspace/llama2-KoAlpaca-Finetuning'\n",
    "RANDOM_SEED = 777\n",
    "HUGGINGFACE_TOKEN = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0a8f41c-74b0-4eec-9fbe-e2dda7a4b810",
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_DIR=os.path.join('/workspace', \".cache\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56eb96b8-b42c-4a53-a90f-b75fc5180905",
   "metadata": {},
   "source": [
    "### 2.2 Model 관련 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67468599-7e90-43cc-be99-096fb2097cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME_OR_PATH = 'meta-llama/Llama-2-7b-hf'\n",
    "TORCH_DTYPE=torch.float16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54b8ddf-4146-4d75-80e8-da26817e01b7",
   "metadata": {},
   "source": [
    "### 2.3 양자화 관련 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab47993e-c06b-4798-ad4b-96e6ee4f7cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_IN_4BIT=True                                   # Enable 4-bit quantization\n",
    "BNB_4BIT_QUANT_TYPE=\"nf4\"                           # BNB 4-bit quantization type\n",
    "BNB_4BIT_COMPUTE_DTYPE=torch.bfloat16               # BNB 4-bit compute dtype\n",
    "BNB_4BIT_USE_DOUBLE_QUANT=True                      # BNB 4-bit use double quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13c74bb-5e3f-420d-b44d-2a129f7edeb6",
   "metadata": {},
   "source": [
    "### 2.4 LoRA 관련 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0abd9d3-31a6-4040-94bb-02ba42a673ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "R=8                                                 # Lora attention dimension\n",
    "LORA_ALPHA=16                                       # Lora alpha parameter\n",
    "LORA_DROPOUT=0.05                                   # Lora dropout probability\n",
    "FAN_IN_FAN_OUT=False                                # Lora fan in fan out\n",
    "BIAS=\"none\"                                         # Lora bias type\n",
    "TARGET_MODULES=[\"q_proj\", \"v_proj\"]                 # Lora target modules\n",
    "INFERENCE_MODE=False                                # Inference mode\n",
    "TASK_TYPE=\"CAUSAL_LM\"                               # Task type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de8ac93-8536-4039-b03f-b19d4748d4ad",
   "metadata": {},
   "source": [
    "### 2.5 Tokenizer 관련 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abfbd741-c3ae-4e33-88e7-c589d85174a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH=512                                     # Max sequence length for tokenizer\n",
    "TRUNCATION=True                                     # Enable/disable truncation\n",
    "RETURN_OVERFLOWING_TOKENS=True                      # Return overflowing tokens info\n",
    "RETURN_LENGTH=True                                  # Return length of encoded inputs\n",
    "PADDING=True                                        # Enable padding to max sequence length\n",
    "PADDING_SIDE=\"right\"                                # The side on which the model should have padding appliedㅠ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f5f841-5740-49b8-bd57-b1d49ea840f5",
   "metadata": {},
   "source": [
    "### 2.6 PROMPT 관련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "725c36df-4e2d-4cab-ab28-a9a0100a14d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"아래는 작업을 설명하는 명령어와 추가적 맥락을 제공하는 입력이 짝을 이루는 예제입니다.\\n\"\n",
    "        \"명령어와 입력을 깊게 이해하고 꼼꼼하고 차분하게 응답을 작성하세요.\\n\\n\"\n",
    "        \n",
    "        \"### Instruction(명령어):%s\\n\"\n",
    "        \"### Input(입력):%s\\n\"\n",
    "        \"### Response(응답):\"\n",
    "    ),\n",
    "    \"prompt_no_input\": (\n",
    "        \"아래는 작업을 설명하는 명령어입니다.\\n\"\n",
    "        \"명령어를 깊게 이해하고 꼼꼼하고 차분하게 응답을 작성하세요.\\n\"\n",
    "        \n",
    "        \"### Instruction(명령어):%s\\n\"\n",
    "        \"### Response(응답):\"\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1a71d7-8acd-4bf5-8545-c06ea1256b65",
   "metadata": {},
   "source": [
    "### 2.7 Evaluate 관련"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424f27a7-6f4a-46d6-91eb-5efb00b1a693",
   "metadata": {},
   "source": [
    "* 모델 Generation 결과 데이터 직렬화 관련\n",
    "    * 모델 추론 시 GPU 자원 사용 및 추론 시간이 너무 오래걸려서 결과 데이터를 직렬화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffb5d412-a299-4db7-8b58-529842c9f171",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVALUATE_DIR = os.path.join(BASE_PATH, 'evaluate', 'pickles')\n",
    "GENERATION_DATA_LIST_PICKLE_NAME = 'sh_llama2-alpaca_1st_1000_output.pkl'\n",
    "GENERATION_DATA_LIST_PICKLE_PATH = os.path.join(EVALUATE_DIR, GENERATION_DATA_LIST_PICKLE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfc912e-9677-49d1-84a5-596a83119760",
   "metadata": {},
   "source": [
    "* 모델 평가 결과 파일로 저장 관련 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92ef66b1-8ed7-4f08-9a76-2432e1c50636",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVALUATION_RESULT_DIR = os.path.join(BASE_PATH, 'evaluate', 'metrics')\n",
    "EVALUATION_RESULT_FILENAME = os.path.join(EVALUATION_RESULT_DIR, 'sh_llama2-alpaca_1th_evaluation.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336fd965-129f-482c-9d0d-6578bc908852",
   "metadata": {},
   "source": [
    "## 3. 데이터셋 살펴보기 및 하나로 합치기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc2928e-85d0-4ca8-a658-5a657563b573",
   "metadata": {},
   "source": [
    "### 3.1 한국어 Aplaca 데이터셋 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28f72900-18b0-40cb-8184-51292fe80874",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join(BASE_PATH, 'datas')\n",
    "DATASET_KO_ALPACA_FINAL_PATH = os.path.join(DATA_PATH, 'final_ko_alpaca_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d25aa29-d9ab-4b62-bd25-0b404ea73835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>이메일에서 스팸을 탐지하기 위한 기계 학습 알고리즘을 만드세요.</td>\n",
       "      <td></td>\n",
       "      <td>이메일 스팸 탐지 알고리즘을 위한 몇 가지 인기있는 기계 학습 모델에는 Suppor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>고기 요리 시 맛술을 사용하는 이유와 대체재는 무엇인가요? 어떤 음식에 맛술을 사용...</td>\n",
       "      <td></td>\n",
       "      <td>안녕하세요! 고기 요리 시 맛술을 사용하는 이유는 냄새와 맛의 개선입니다. 근육 안...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>대화를 시작하기 위해 트윗을 작성합니다.</td>\n",
       "      <td></td>\n",
       "      <td>'안녕하세요! 오늘 날씨가 참 좋네요!'  (트윗 예시)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>저녁과 밤의 구분 기준은 무엇인가요? 저녁 8시가 맞나요? 밤 8시가 맞나요?</td>\n",
       "      <td></td>\n",
       "      <td>저녁과 밤을 구분하는 기준은 명확히 정의되어 있지 않습니다. '저녁'은 해가 지고 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>이 문장의 시작 부분에 전환 단어를 삽입하세요.</td>\n",
       "      <td>그는 오랫동안 수색한 끝에 보물을 찾았습니다.</td>\n",
       "      <td>그러나, 그는 오랫동안 수색한 끝에 보물을 찾았습니다.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         instruction  \\\n",
       "0                이메일에서 스팸을 탐지하기 위한 기계 학습 알고리즘을 만드세요.   \n",
       "1  고기 요리 시 맛술을 사용하는 이유와 대체재는 무엇인가요? 어떤 음식에 맛술을 사용...   \n",
       "2                             대화를 시작하기 위해 트윗을 작성합니다.   \n",
       "3        저녁과 밤의 구분 기준은 무엇인가요? 저녁 8시가 맞나요? 밤 8시가 맞나요?   \n",
       "4                         이 문장의 시작 부분에 전환 단어를 삽입하세요.   \n",
       "\n",
       "                       input  \\\n",
       "0                              \n",
       "1                              \n",
       "2                              \n",
       "3                              \n",
       "4  그는 오랫동안 수색한 끝에 보물을 찾았습니다.   \n",
       "\n",
       "                                              output  \n",
       "0  이메일 스팸 탐지 알고리즘을 위한 몇 가지 인기있는 기계 학습 모델에는 Suppor...  \n",
       "1  안녕하세요! 고기 요리 시 맛술을 사용하는 이유는 냄새와 맛의 개선입니다. 근육 안...  \n",
       "2                    '안녕하세요! 오늘 날씨가 참 좋네요!'  (트윗 예시)  \n",
       "3  저녁과 밤을 구분하는 기준은 명확히 정의되어 있지 않습니다. '저녁'은 해가 지고 ...  \n",
       "4                     그러나, 그는 오랫동안 수색한 끝에 보물을 찾았습니다.  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KO_ALPACA_FINAL_PATH = os.path.join(BASE_PATH, DATASET_KO_ALPACA_FINAL_PATH)\n",
    "\n",
    "with open(KO_ALPACA_FINAL_PATH, 'r', encoding='utf-8') as file:\n",
    "    ko_alpaca_final = json.load(file)\n",
    "\n",
    "df_ko_alpaca_final = pd.DataFrame(ko_alpaca_final)\n",
    "df_ko_alpaca_final.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75964711-34a4-4ef5-94b7-9772eaee5895",
   "metadata": {},
   "source": [
    "### 3.2 평가를 위해 한국어 Aplaca 데이터셋 1000개의 샘플 뽑기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fc4c263-a25b-44dd-8937-4ef26d4cb079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17666</th>\n",
       "      <td>고객 서비스 봇에 가장 적합한 어조를 파악하세요.</td>\n",
       "      <td></td>\n",
       "      <td>고객 서비스에서 호칭과 제품 또는 서비스에 대한 지식을 바탕으로 열정적인 어조를 사...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69026</th>\n",
       "      <td>동물 멸종 사건에 대한 뉴스 기사의 헤드라인을 생성합니다.</td>\n",
       "      <td></td>\n",
       "      <td>동물학자들이 말하는 대규모 멸종 사건이 상상이상으로 빨리 벌어지고 있습니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20869</th>\n",
       "      <td>예산 수립을 위한 계획 만들기</td>\n",
       "      <td></td>\n",
       "      <td>예산 수립 계획을 만들 때는 다음과 같은 단계를 따릅니다. 예산 오브젝티브 설정, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68447</th>\n",
       "      <td>\"Dear John\"이라는 표현의 어원은 무엇일까요? 왜 이별 편지나 절교장을 의미...</td>\n",
       "      <td></td>\n",
       "      <td>\"Dear John letter\"는 이별 편지나 절교장을 뜻하는 표현으로 사용됩니다...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15376</th>\n",
       "      <td>피보나치 수열의 처음 10개의 숫자를 출력하는 함수를 Java로 작성하십시오.</td>\n",
       "      <td></td>\n",
       "      <td>```java\\npublic class Fibonacci {\\n\\n  public ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7944</th>\n",
       "      <td>지구 온난화로 인해 발생할 수 있는 다섯 가지 문제를 브레인스토밍하십시오.</td>\n",
       "      <td></td>\n",
       "      <td>지구온난화로 인해 발생할 수 있는 다섯 가지 문제는 먹을 것 부족, 극심한 기후변화...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>\"별이 태어났다\"라는 문구를 다른 두 가지 방법으로 다시 쓰십시오.</td>\n",
       "      <td></td>\n",
       "      <td>New star is born, A star has arisen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61640</th>\n",
       "      <td>다음 기사의 헤드라인을 작성합니다: \"스타틴이 심장 마비 위험을 줄인다는 연구 결과...</td>\n",
       "      <td></td>\n",
       "      <td>\"연구 결과, 스타틴은 심장 마비 위험을 줄인다.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43819</th>\n",
       "      <td>해변의 자연물을 사용하여 게임을 디자인하세요.</td>\n",
       "      <td></td>\n",
       "      <td>해변에서 찾은 조개껍질을 이용하여, 조개찾기 대회를 개최해보세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56612</th>\n",
       "      <td>스코틀랜드에서 남자가 치마를 입는 이유는 무엇인가요?</td>\n",
       "      <td></td>\n",
       "      <td>스코틀랜드에서 남성이 치마를 입는 이유는 여러 가지 주장이 있으나, 역사적으로는 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             instruction input  \\\n",
       "17666                        고객 서비스 봇에 가장 적합한 어조를 파악하세요.         \n",
       "69026                   동물 멸종 사건에 대한 뉴스 기사의 헤드라인을 생성합니다.         \n",
       "20869                                   예산 수립을 위한 계획 만들기         \n",
       "68447  \"Dear John\"이라는 표현의 어원은 무엇일까요? 왜 이별 편지나 절교장을 의미...         \n",
       "15376        피보나치 수열의 처음 10개의 숫자를 출력하는 함수를 Java로 작성하십시오.         \n",
       "...                                                  ...   ...   \n",
       "7944           지구 온난화로 인해 발생할 수 있는 다섯 가지 문제를 브레인스토밍하십시오.         \n",
       "1741               \"별이 태어났다\"라는 문구를 다른 두 가지 방법으로 다시 쓰십시오.         \n",
       "61640  다음 기사의 헤드라인을 작성합니다: \"스타틴이 심장 마비 위험을 줄인다는 연구 결과...         \n",
       "43819                          해변의 자연물을 사용하여 게임을 디자인하세요.         \n",
       "56612                      스코틀랜드에서 남자가 치마를 입는 이유는 무엇인가요?         \n",
       "\n",
       "                                                  output  \n",
       "17666  고객 서비스에서 호칭과 제품 또는 서비스에 대한 지식을 바탕으로 열정적인 어조를 사...  \n",
       "69026         동물학자들이 말하는 대규모 멸종 사건이 상상이상으로 빨리 벌어지고 있습니다.  \n",
       "20869  예산 수립 계획을 만들 때는 다음과 같은 단계를 따릅니다. 예산 오브젝티브 설정, ...  \n",
       "68447  \"Dear John letter\"는 이별 편지나 절교장을 뜻하는 표현으로 사용됩니다...  \n",
       "15376  ```java\\npublic class Fibonacci {\\n\\n  public ...  \n",
       "...                                                  ...  \n",
       "7944   지구온난화로 인해 발생할 수 있는 다섯 가지 문제는 먹을 것 부족, 극심한 기후변화...  \n",
       "1741                 New star is born, A star has arisen  \n",
       "61640                       \"연구 결과, 스타틴은 심장 마비 위험을 줄인다.\"  \n",
       "43819               해변에서 찾은 조개껍질을 이용하여, 조개찾기 대회를 개최해보세요.  \n",
       "56612  스코틀랜드에서 남성이 치마를 입는 이유는 여러 가지 주장이 있으나, 역사적으로는 1...  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ko_alpaca_final_sampled = df_ko_alpaca_final.sample(1000, random_state=RANDOM_SEED)\n",
    "df_ko_alpaca_final_sampled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412d638f-ac2e-4653-b4e3-f497803a1db6",
   "metadata": {},
   "source": [
    "### 3.2 평가를 위해 한국어 Aplaca 데이터셋 1000개의 샘플 뽑기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f747589-9b35-4212-b630-355b70082bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_prompts = []\n",
    "for _, row in df_ko_alpaca_final_sampled.iterrows():\n",
    "    instruction = row['instruction']\n",
    "    input_text = row['input']\n",
    "    if input_text:\n",
    "        formatted_prompts.append(PROMPT_DICT['prompt_input'] % (instruction, input_text))\n",
    "    else:\n",
    "        formatted_prompts.append(PROMPT_DICT['prompt_no_input'] % instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "267aec8f-7339-4e4d-91f3-6591a5c24759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['아래는 작업을 설명하는 명령어입니다.\\n명령어를 깊게 이해하고 꼼꼼하고 차분하게 응답을 작성하세요.\\n### Instruction(명령어):고객 서비스 봇에 가장 적합한 어조를 파악하세요.\\n### Response(응답):',\n",
       " '아래는 작업을 설명하는 명령어입니다.\\n명령어를 깊게 이해하고 꼼꼼하고 차분하게 응답을 작성하세요.\\n### Instruction(명령어):동물 멸종 사건에 대한 뉴스 기사의 헤드라인을 생성합니다.\\n### Response(응답):']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_prompts[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e7c321-9ddd-4130-b2cc-e1e753001a5e",
   "metadata": {},
   "source": [
    "## 4. 모델 호출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf6bafc-f120-4a63-94d4-4e1e6a560c31",
   "metadata": {},
   "source": [
    "### 4.1 모델 학습을 위한 기본 확인사항 내용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0a29e9-ee01-4da8-ae8f-12f206d26554",
   "metadata": {},
   "source": [
    "* 모델 파라미터 정보 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2a7d1b4-1ffa-4cb4-bddd-f91bb481462b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    all_params = sum(p.numel() for p in model.parameters())\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_params} || trainable%: {100 * trainable_params / all_params}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5c1fbf-709d-4a37-9888-d0edde974e8a",
   "metadata": {},
   "source": [
    "* GPU 분산학습 설정 사용 유무 점검"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e46ca01-89fb-4484-bdbc-072ae4e5d475",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddp = False\n",
    "\n",
    "def get_device_map():\n",
    "    print(f\"num_gpus: {torch.cuda.device_count()}\")\n",
    "    world_size = int(os.environ.get(\"WORLD_SIZE\", torch.cuda.device_count()))\n",
    "    print(f\"world_size: {world_size}\")\n",
    "    ddp = world_size != 1\n",
    "    if ddp:\n",
    "        device_map = {\"\": int(os.environ.get(\"LOCAL_RANK\") or 0)}\n",
    "        GRADIENT_ACCUMULATION_STEPS = TRAIN_BATCH_SIZE // world_size\n",
    "        if GRADIENT_ACCUMULATION_STEPS == 0:\n",
    "            GRADIENT_ACCUMULATION_STEPS = 1\n",
    "        print(f\"ddp is on - gradient_accumulation_steps: {GRADIENT_ACCUMULATION_STEPS}\")\n",
    "    else:\n",
    "        device_map = \"auto\"\n",
    "        print(\"ddp is off\")\n",
    "\n",
    "    return device_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3d70bf-e8bc-4533-a6d8-8f39c5540f26",
   "metadata": {},
   "source": [
    "## 4.2 모델 Load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af73e42-081b-4bca-8569-63768bb5109c",
   "metadata": {},
   "source": [
    "* 양자화 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4847d84f-65a2-4931-8d2e-d78e366115f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=LOAD_IN_4BIT,\n",
    "    bnb_4bit_use_double_quant=BNB_4BIT_USE_DOUBLE_QUANT,\n",
    "    bnb_4xqbit_quant_type=BNB_4BIT_QUANT_TYPE,\n",
    "    bnb_4bit_computxe_dtype=BNB_4BIT_COMPUTE_DTYPE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55f8f3b-4f3a-4a3a-bc18-cb65ea5d7756",
   "metadata": {},
   "source": [
    "* 모델 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44d18530-2c5f-4cea-b967-470eaa367a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_gpus: 1\n",
      "world_size: 1\n",
      "ddp is off\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12a9ca486ac9420e9d297995f78d5c98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 262410240 || all params: 3500412928 || trainable%: 7.496550989769399\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME_OR_PATH,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=get_device_map(),\n",
    "    cache_dir=CACHE_DIR,\n",
    "    token=HUGGINGFACE_TOKEN\n",
    ")\n",
    "\n",
    "print_trainable_parameters(model)\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f42641b-7b8d-4f2b-864f-ea1d2215e570",
   "metadata": {},
   "source": [
    "## 4.3 LoRA Adapter 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "370d5dff-bc29-4271-af67-1f5bbc279254",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/lora/bnb.py:229: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 0 || all params: 3500412928 || trainable%: 0.0\n"
     ]
    }
   ],
   "source": [
    "model = PeftModel.from_pretrained(\n",
    "    model,\n",
    "    CHECKPOINT_DIR,\n",
    "    torch_dtype=torch.float16,\n",
    "    quantization_config=bnb_config,\n",
    ")\n",
    "model = model.merge_and_unload()\n",
    "print_trainable_parameters(model)\n",
    "\n",
    "\n",
    "if not ddp and torch.cuda.device_count() > 1:\n",
    "    model.is_parallelizable = True\n",
    "    model.model_parallel = True\n",
    "    print(\"not ddp - trying its own DataParallelism\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "403cd075-61bf-488a-a6b8-9bc6f6586950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eaad891-4961-46fc-8e2b-d8e3d0c52ee2",
   "metadata": {},
   "source": [
    "### 4.3 Tokenizer 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8be6c09-a295-47a0-b348-5ad33bcc1d4b",
   "metadata": {},
   "source": [
    "* 모델 tokenizer를 통해 사용할 데이터셋을 분석하여 입력 데이터의 길이 분포를 파악"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "026bcdcd-dd9f-41c8-9c8b-3c6791bb6310",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME_OR_PATH, cache_dir=CACHE_DIR, use_add_token=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f0206a-6472-49a9-877b-f6860c546169",
   "metadata": {},
   "source": [
    "## 5. 모델을 통한 추론"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa4c302-58ce-4286-9945-02b663338f05",
   "metadata": {},
   "source": [
    "### 5.1 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f8fc180-028e-4d95-bc73-7cc43038a816",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextStreamer\n",
    "\n",
    "streamer = TextStreamer(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "133c0c31-a565-442b-b3e5-9ad5266f6552",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:430: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "generation_config = GenerationConfig(\n",
    "    temperature=0.2,\n",
    "    top_p=0.9,\n",
    "    top_k=50,\n",
    "    max_new_tokens=MAX_LENGTH,\n",
    "    early_stopping=True,\n",
    "    do_sample=True,\n",
    "    repetition_penalty=1.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95015847-d162-4785-983f-25c6d2fcc126",
   "metadata": {},
   "outputs": [],
   "source": [
    "streamer = TextStreamer(tokenizer)\n",
    "\n",
    "def gen(instruction, input=None):\n",
    "    # query = f\"### instruction: {x}\\n\\n### Response: \"\n",
    "    query = PROMPT_DICT['prompt_no_input'] % instruction\n",
    "    if input:\n",
    "        query = PROMPT_DICT['prompt_input'] % (instruction, input)\n",
    "    generated_id = model.generate(\n",
    "        **tokenizer(\n",
    "            query,\n",
    "            return_tensors='pt',\n",
    "            return_token_type_ids=False\n",
    "        ).to('cuda'),\n",
    "        generation_config=generation_config,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        streamer=streamer,\n",
    "    )\n",
    "    generated_text = tokenizer.decode(generated_id[0], skip_special_tokens=True)\n",
    "\n",
    "    response_start_idx = generated_text.find(\"### Response(응답):\") + len(\"### Response(응답):\")\n",
    "    response = generated_text[response_start_idx:].strip()\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033857f5-1c2f-4350-83df-3085f1733b61",
   "metadata": {},
   "source": [
    "## 일반 상식 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3802c5e0-ad7f-496e-a1cc-ad24496a54d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> 아래는 작업을 설명하는 명령어입니다.\n",
      "\b명령어를 깊게 이해하고 꼼꼼하고 차분하게 응답을 작성하세요.\n",
      "### Instruction(명령어):\n",
      "파이썬 공부를 하고 싶습니다. 파이썬을 처음 공부해봅니다. 어떻게 공부를 시작하면 좋을까요?\n",
      "\n",
      "### "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:430: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response(응답):파이썬에 대한 기본적인 지식은 약간의 웹 개발 경험과 함께 쉽게 익히실 수 있습니다. 그러나 완전히 파이썬을 익힐 때는 직접 문제를 해결하는 방법을 사용하는 것이 가장 좋습니다. 즉, 문제를 해결하는 동안 자신이 무엇을 어떻게 해야하는지 생각하는 것이 중요합니다. 이러한 방법들은 여러 가지가 있습니다. 예를 들어, 문제를 해결하는 동안 코드를 작성하는 것은 좋은 방법입니다. 또한, 문제를 해결하는 동안 다른 사람들이 해결하는 방법을 보는 것도 유용합니다. 이러한 방법들은 모든 문제를 해결하는 것보다는 일부 문제를 해결하는 것을 위주합니다. 따라서 파이썬을 공부하는 동안 문제를 해결하는 방법을 찾아내는 것이 중요합니다.</s>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'파이썬에 대한 기본적인 지식은 약간의 웹 개발 경험과 함께 쉽게 익히실 수 있습니다. 그러나 완전히 파이썬을 익힐 때는 직접 문제를 해결하는 방법을 사용하는 것이 가장 좋습니다. 즉, 문제를 해결하는 동안 자신이 무엇을 어떻게 해야하는지 생각하는 것이 중요합니다. 이러한 방법들은 여러 가지가 있습니다. 예를 들어, 문제를 해결하는 동안 코드를 작성하는 것은 좋은 방법입니다. 또한, 문제를 해결하는 동안 다른 사람들이 해결하는 방법을 보는 것도 유용합니다. 이러한 방법들은 모든 문제를 해결하는 것보다는 일부 문제를 해결하는 것을 위주합니다. 따라서 파이썬을 공부하는 동안 문제를 해결하는 방법을 찾아내는 것이 중요합니다.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen(\"\"\"\n",
    "파이썬 공부를 하고 싶습니다. 파이썬을 처음 공부해봅니다. 어떻게 공부를 시작하면 좋을까요?\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4221bd15-ddf8-465c-853c-460b161e6cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> 아래는 작업을 설명하는 명령어와 추가적 맥락을 제공하는 입력이 짝을 이루는 예제입니다.\n",
      "명령어와 입력을 깊게 이해하고 꼼꼼하고 차분하게 응답을 작성하세요.\n",
      "\n",
      "### Instruction(명령어):컴퓨터 공학과의 일반적인 커리큘럼은 어떻게 되나요?\n",
      "### Input(입력):답변을 할 때, 2개의 문장으로 작성해주세요.\n",
      "### Response(응답):컴퓨터 공학과에서는 기초 수업부터 전공 수업까지 진행됩니다. 기초 수업에서는 C/C++를 비롯한 프로그래밍 언어를 배우며, 전공 수업에서는 데이터베이스, 소프트웨어 시스템, 운영체제 등 여러 전공 분야를 선택할 수 있습니다.</s>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'컴퓨터 공학과에서는 기초 수업부터 전공 수업까지 진행됩니다. 기초 수업에서는 C/C++를 비롯한 프로그래밍 언어를 배우며, 전공 수업에서는 데이터베이스, 소프트웨어 시스템, 운영체제 등 여러 전공 분야를 선택할 수 있습니다.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen(\n",
    "    instruction='컴퓨터 공학과의 일반적인 커리큘럼은 어떻게 되나요?',\n",
    "    input='답변을 할 때, 2개의 문장으로 작성해주세요.'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e5e1e4-5e25-45a0-9792-cfa5e55772e5",
   "metadata": {},
   "source": [
    "## 단순 코드 계산 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "78ba443a-ff89-4de8-85f8-1c11ba859c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> 아래는 작업을 설명하는 명령어입니다.\n",
      "\b명령어를 깊게 이해하고 꼼꼼하고 차분하게 응답을 작성하세요.\n",
      "### Instruction(명령어):\n",
      "파이썬을 통해 1부터 10까지의 총합을 구하는 코드를 작성해주세요\n",
      "\n",
      "### Response(응답):```python\n",
      "sum = 0\n",
      "for i in range(1, 11):\n",
      "   sum += i\n",
      "print(\"The sum of numbers from 1 to 10 is:\", sum)\n",
      "```</s>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'```python\\nsum = 0\\nfor i in range(1, 11):\\n    sum += i\\nprint(\"The sum of numbers from 1 to 10 is:\", sum)\\n```'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen(\"\"\"\n",
    "파이썬을 통해 1부터 10까지의 총합을 구하는 코드를 작성해주세요\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b189d88d-4dc4-4873-8085-4499fd45bd2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> 아래는 작업을 설명하는 명령어입니다.\n",
      "\b명령어를 깊게 이해하고 꼼꼼하고 차분하게 응답을 작성하세요.\n",
      "### Instruction(명령어):\n",
      "자바 언어를 통해 1부터 15까지 곱셈하는 코드를 작성해주세요\n",
      "\n",
      "### Response(응답):```java\n",
      "int i = 1;\n",
      "for (i = 2; i <= 15; i++) {\n",
      "   System.out.println(\"\" + i);\n",
      "}\n",
      "```</s>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'```java\\nint i = 1;\\nfor (i = 2; i <= 15; i++) {\\n    System.out.println(\"\" + i);\\n}\\n```'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen(\"\"\"\n",
    "자바 언어를 통해 1부터 15까지 곱셈하는 코드를 작성해주세요\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc5abf9-f759-4093-a04a-3ad28cbe7837",
   "metadata": {},
   "source": [
    "## 요약 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a247664-11d8-4937-9204-b931c2c45757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "매<s> 아래는 작업을 설명하는 명령어와 추가적 맥락을 제공하는 입력이 짝을 이루는 예제입니다.\n",
      "명령어와 입력을 깊게 이해하고 꼼꼼하고 차분하게 응답을 작성하세요.\n",
      "\n",
      "### Instruction(명령어):\n",
      "아래와 같은 기사가 있습니다. 기사의 핵심 내용을 추려서 간단하게 요약해주세요.\n",
      "\n",
      "### Input(입력):\n",
      "토트넘(잉글랜드)의 3연승을 이끈 '캡틴' 손흥민(31)이 맨 오브 더 매치(MOM)에 선정됐다. \n",
      "손흥민은 크리스마스 이브인 24일(한국 시각) 영국 런던의 토트넘 홋스퍼 스타디움에서 열린 에버턴과 2023-2024시즌 잉글랜드 프리미어리그(EPL) 18라운드 홈 경기에서 팀의 두 번째 골을 터뜨렸다. \n",
      "토트넘은 손흥민의 득점에 힘입어 2 대 1 승리를 거뒀다. \n",
      "이로써 토트넘은 3연승 행진을 이어갔고, 11승 3무 4패 승점 36을 기록했다. 한 경기를 덜 치른 맨체스터 시티(승점 34)를 제치고 4위로 올라섰다.\n",
      "손흥민은 이날도 왼쪽 측면 공격수로 나섰다. 지난 16라운드 뉴캐슬전(1골 2도움)부터 왼쪽 측면에서 최고 윙어의 면모를 유감없이 발휘하고 있다. \n",
      "17라운드 노팅엄 포레스트전에서는 공격 포인트를 올리지 못했으나, 이날 2경기 만에 다시 득점포를 가동했다.\n",
      "리그 11호 골을 터뜨린 손흥민은 무함마드 살라흐(리버풀), 재러드 보웬(웨스트햄)과 나란히 득점 공동 3위에 올랐다. \n",
      "1위는 14골의 엘링 홀란(맨체스터 시티), 2위는 12골의 도미닉 솔란케(본머스)다.\n",
      "또 손흥민은 리그 반환점을 1경기 남겨둔 시점에서 벌써 지난 시즌 득점 기록을 넘어섰다. \n",
      "스포츠 탈장 부상 여파로 고전했던 지난 시즌에는 10골 6도움을 기록했다. \n",
      "도움 4개를 기록 중인 그는 지난 시즌 공격 포인트 기록 돌파도 눈앞에 두고 있다.\n",
      "EPL 통산 득점 랭킹에서는 아스널의 레전드 이안 라이트(113골)을 넘어섰다. \n",
      "114골로 단독 23위에 오른 손흥민은 120골로 공동 21위인 라힘 스털링(첼시), 스티븐 제라드를 6골 차로 쫓고 있다.\n",
      "손흥민은 경기 후 EPL 사무국이 22947명의 팬을 상대로 진행한 투표에서 67.7%의 압도적인 지지를 받아 MOM에 오르는 영예를 안았다. \n",
      "팀 동료인 굴리엘모 비카리오(15.1%), 페드로 포로(7.8%) 등을 크게 따돌렸다.\n",
      "풀타임을 뛴 손흥민은 1골을 포함해 슈팅 2회, 패스 성공률 71%(24/34), 기회 창출 1회, 볼 터치 56회, 드리블 성공 43%(3/7) 등을 기록했다. \n",
      "축구 통계 매체 '풋몹'은 손흥민에게 팀 내 4번째로 높은 평점 7.8을 부여했다.\n",
      "\n",
      "### Response(응답): 손흥민이 맨 오브 더 매치에 선정된 것은 자신의 좋은 활약에 따른 것이며, 손흥민은 최근 3연승을 이끌었다. 손흥민은 왼쪽 측면 공격수로 나섰다. 손흥민은 맨체스터 시티와 본머스 등 강력한 라이벌들과 경합하며 많은 경기를 뛰고 있다.</s>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'손흥민이 맨 오브 더 매치에 선정된 것은 자신의 좋은 활약에 따른 것이며, 손흥민은 최근 3연승을 이끌었다. 손흥민은 왼쪽 측면 공격수로 나섰다. 손흥민은 맨체스터 시티와 본머스 등 강력한 라이벌들과 경합하며 많은 경기를 뛰고 있다.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen(\"\"\"\n",
    "아래와 같은 기사가 있습니다. 기사의 핵심 내용을 추려서 간단하게 요약해주세요.\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "토트넘(잉글랜드)의 3연승을 이끈 '캡틴' 손흥민(31)이 맨 오브 더 매치(MOM)에 선정됐다. \n",
    "손흥민은 크리스마스 이브인 24일(한국 시각) 영국 런던의 토트넘 홋스퍼 스타디움에서 열린 에버턴과 2023-2024시즌 잉글랜드 프리미어리그(EPL) 18라운드 홈 경기에서 팀의 두 번째 골을 터뜨렸다. \n",
    "토트넘은 손흥민의 득점에 힘입어 2 대 1 승리를 거뒀다. \n",
    "이로써 토트넘은 3연승 행진을 이어갔고, 11승 3무 4패 승점 36을 기록했다. 한 경기를 덜 치른 맨체스터 시티(승점 34)를 제치고 4위로 올라섰다.\n",
    "손흥민은 이날도 왼쪽 측면 공격수로 나섰다. 지난 16라운드 뉴캐슬전(1골 2도움)부터 왼쪽 측면에서 최고 윙어의 면모를 유감없이 발휘하고 있다. \n",
    "17라운드 노팅엄 포레스트전에서는 공격 포인트를 올리지 못했으나, 이날 2경기 만에 다시 득점포를 가동했다.\n",
    "리그 11호 골을 터뜨린 손흥민은 무함마드 살라흐(리버풀), 재러드 보웬(웨스트햄)과 나란히 득점 공동 3위에 올랐다. \n",
    "1위는 14골의 엘링 홀란(맨체스터 시티), 2위는 12골의 도미닉 솔란케(본머스)다.\n",
    "또 손흥민은 리그 반환점을 1경기 남겨둔 시점에서 벌써 지난 시즌 득점 기록을 넘어섰다. \n",
    "스포츠 탈장 부상 여파로 고전했던 지난 시즌에는 10골 6도움을 기록했다. \n",
    "도움 4개를 기록 중인 그는 지난 시즌 공격 포인트 기록 돌파도 눈앞에 두고 있다.\n",
    "EPL 통산 득점 랭킹에서는 아스널의 레전드 이안 라이트(113골)을 넘어섰다. \n",
    "114골로 단독 23위에 오른 손흥민은 120골로 공동 21위인 라힘 스털링(첼시), 스티븐 제라드를 6골 차로 쫓고 있다.\n",
    "손흥민은 경기 후 EPL 사무국이 22947명의 팬을 상대로 진행한 투표에서 67.7%의 압도적인 지지를 받아 MOM에 오르는 영예를 안았다. \n",
    "팀 동료인 굴리엘모 비카리오(15.1%), 페드로 포로(7.8%) 등을 크게 따돌렸다.\n",
    "풀타임을 뛴 손흥민은 1골을 포함해 슈팅 2회, 패스 성공률 71%(24/34), 기회 창출 1회, 볼 터치 56회, 드리블 성공 43%(3/7) 등을 기록했다. \n",
    "축구 통계 매체 '풋몹'은 손흥민에게 팀 내 4번째로 높은 평점 7.8을 부여했다.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75835b27-3163-4787-827e-8637d5259b5a",
   "metadata": {},
   "source": [
    "* 요약을 할때 모델이 2문장으로 잘 요약했지만, 두 문장의 답변을 얻기 위해 instruction에 별도의 설명을 추가하였음\n",
    "* 많은 경우에 있어 n문장으로 요약을 해달라고 하면, n문장으로 답변을 해주지는 않음.\n",
    "    * koalpaca 데이터만 학습시켰기 때문이며, 다음의 논리를 이해하기 위한 데이터셋을 추가하여 학습시킨다면 잘 답변을 해줄 것이라 생각이 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e524f88a-6b15-459b-b78d-0baf17627f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "�<s> 아래는 작업을 설명하는 명령어와 추가적 맥락을 제공하는 입력이 짝을 이루는 예제입니다.\n",
      "명령어와 입력을 깊게 이해하고 꼼꼼하고 차분하게 응답을 작성하세요.\n",
      "\n",
      "### Instruction(명령어):아래와 같은 문장들이 있습니다. 답변을 할때 이 문장들을 2개의 문장으로 요약해주세요. 문장이 2개라는 것은 개행문자가 2개인 것을 의미합니다.\n",
      "### Input(입력):\n",
      "FLAN (Fine-tuned LAnguage Net) 모델은 자연어 처리(NLP) 과제들을 해결하기 위해 'instruction tuning'이라는 기법을 사용하는 언어 모델입니다.\n",
      "이 모델의 핵심 아이디어는 다양한 NLP 과제를 자연어 지시사항 형태로 변형하여 이러한 과제들을 풀도록 fine-tuning하는 것입니다.\n",
      "이를 통해 FLAN 모델은 번역, 상식 추론, 감정 분류 등을 포함한 다양한 NLP 과제를 수행할 수 있도록 fine-tuning 됩니다​.\n",
      "\n",
      "FLAN의 연구 결과에 따르면, 이 모델은 zero-shot 시나리오에서 GPT-3보다 우수한 결과를 보였으며, 많은 task에서는 supervised model과 비슷한 성능을 달성했습니다.\n",
      "특히 자연어 추론(NLI)과 질문응답(QA) 작업에서 효과적이었습니다.\n",
      "Google Research Blog에서는 FLAN이 언어 모델을 사용하여 특정 실제 과제에 대한 지식을 어떻게 풀어내는지에 대해 설명합니다.\n",
      "전통적으로는 레이블이 붙은 데이터셋을 이용해 fine-tuning하는 방법이 많이 사용되었지만, FLAN은 다양한 종류의 지시사항에 대해 모델을 fine-tuning함으로써, 특정 과제가 아닌 일반적인 NLP 과제들을 해결할 수 있게 만듭니다.\n",
      "\n",
      "### Response(응답):FLAN은 자연어 처리(NLP) 과제들을 해결하기 위해 'instruction tuning'이라는 기법을 사용하는 언어 모델입니다. 이를 통해 FLAN 모델은 번역, 상식 추론, 감정 분류 등을 포함한 다양한 NLP 과제를 수행할 수 있도록 fine-tuning 됩니다.</s>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"FLAN은 자연어 처리(NLP) 과제들을 해결하기 위해 'instruction tuning'이라는 기법을 사용하는 언어 모델입니다. 이를 통해 FLAN 모델은 번역, 상식 추론, 감정 분류 등을 포함한 다양한 NLP 과제를 수행할 수 있도록 fine-tuning 됩니다.\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen(\n",
    "    instruction='아래와 같은 문장들이 있습니다. 답변을 할때 이 문장들을 2개의 문장으로 요약해주세요. 문장이 2개라는 것은 개행문자가 2개인 것을 의미합니다.',\n",
    "    input=\n",
    "\"\"\"\n",
    "FLAN (Fine-tuned LAnguage Net) 모델은 자연어 처리(NLP) 과제들을 해결하기 위해 'instruction tuning'이라는 기법을 사용하는 언어 모델입니다.\n",
    "이 모델의 핵심 아이디어는 다양한 NLP 과제를 자연어 지시사항 형태로 변형하여 이러한 과제들을 풀도록 fine-tuning하는 것입니다.\n",
    "이를 통해 FLAN 모델은 번역, 상식 추론, 감정 분류 등을 포함한 다양한 NLP 과제를 수행할 수 있도록 fine-tuning 됩니다​.\n",
    "\n",
    "FLAN의 연구 결과에 따르면, 이 모델은 zero-shot 시나리오에서 GPT-3보다 우수한 결과를 보였으며, 많은 task에서는 supervised model과 비슷한 성능을 달성했습니다.\n",
    "특히 자연어 추론(NLI)과 질문응답(QA) 작업에서 효과적이었습니다.\n",
    "Google Research Blog에서는 FLAN이 언어 모델을 사용하여 특정 실제 과제에 대한 지식을 어떻게 풀어내는지에 대해 설명합니다.\n",
    "전통적으로는 레이블이 붙은 데이터셋을 이용해 fine-tuning하는 방법이 많이 사용되었지만, FLAN은 다양한 종류의 지시사항에 대해 모델을 fine-tuning함으로써, 특정 과제가 아닌 일반적인 NLP 과제들을 해결할 수 있게 만듭니다.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96a6c97-e4f2-44be-9338-92934497a168",
   "metadata": {},
   "source": [
    "## One-shot 예제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e1b051-3236-4a78-b164-6189cd8e2d8a",
   "metadata": {},
   "source": [
    "* 학습되지 않아 LLM에 지식이 존재하지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d5e7aaac-c451-4e6c-9605-0f68e510e94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> 아래는 작업을 설명하는 명령어입니다.\n",
      "\b명령어를 깊게 이해하고 꼼꼼하고 차분하게 응답을 작성하세요.\n",
      "### Instruction(명령어):\n",
      "솔트룩스 회사의 루시아 솔루션에 대해서 설명해주세요.\n",
      "\n",
      "### Response(응답):Lucid Solutions은 미국 워싱턴 D.C. 지역에 위치한 소프트웨어 개발 회사로, 2014년 설립되었습니다. 회사는 정부 기관과 비영리 단체들에게 전자 문서 관리 시스템인 Lucid Viewer를 제공합니다. 이 시스템은 정부 기관과 비영리 단체들에게 전자 문서 관리 시스템인 Lucid Viewer를 제공합니다.</s>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Lucid Solutions은 미국 워싱턴 D.C. 지역에 위치한 소프트웨어 개발 회사로, 2014년 설립되었습니다. 회사는 정부 기관과 비영리 단체들에게 전자 문서 관리 시스템인 Lucid Viewer를 제공합니다. 이 시스템은 정부 기관과 비영리 단체들에게 전자 문서 관리 시스템인 Lucid Viewer를 제공합니다.'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen(\"\"\"\n",
    "솔트룩스 회사의 루시아 솔루션에 대해서 설명해주세요.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa7b22d-e2da-4983-a775-e8981e4ca3cc",
   "metadata": {},
   "source": [
    "* 지식 하나를 주입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "af6504d1-3fa8-457d-af05-8a7c21dd8a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> 아래는 작업을 설명하는 명령어입니다.\n",
      "\b명령어를 깊게 이해하고 꼼꼼하고 차분하게 응답을 작성하세요.\n",
      "### Instruction(명령어):\n",
      "질문 : 솔트룩스 회사의 루시아 솔루션에 대해서 설명해주세요. 솔트룩스 및 루시아에 대한 정보를 External Generated Knowledge로 드립니다.\n",
      "\n",
      "```\n",
      "인공지능 기업 솔트룩스(대표 이경일)는 ‘LUXIA Is All You Need–생성 AI 시대, 모든 것이 달라집니다'를 주제로 7일, 서울 코엑스 오디토리움에서 AI 컨퍼런스 'SAC 2023'을 개최했다.\n",
      "\n",
      "이날 행사에서는 솔트룩스가 올해 초 금융권 컨퍼런스를 통해 처음 공개한 초거대 언어모델(LLM) ‘루시아(LUXIA)’와 그 생태계가 본격적으로 소개됐다. 온오프라인 하이브리드 형태로 개최된 이번 행사의 사전 참가 신청자는 약 2,700명에 달했다.\n",
      "\n",
      "솔트룩스 이경일 대표는 키노트를 통해 도서 420만 권 분량을 학습한 자체 GPT 모델에 실시간 정보와 전문 지식을 활용해 환각 현상을 획기적으로 감소시킨 루시아GPT와 다양한 노코드 도구들을 선보였다. 또한 “처음 설립되었을 때 세상 모든 사람이 자유롭게 지식 소통하는 세상을 만들겠다는 미션을 가지고 있었던 솔트룩스는, 이제 오직 사람을 위한 인공지능 사람만을 위한 루시아GPT를 만들고 이를 통해 또 다른 성장을 시작하고자 한다”라고 말했다.  \n",
      "\n",
      "다양한 환경에 맞춤형으로 도입 가능한 똑똑한 루시아(LUXIA)\n",
      "\n",
      "루시아는 AI 데이터 구축 관련 정부 사업뿐 아니라 특허청, 행정안전부 등 다양한 분야의 사업을 수행하며 솔트룩스가 축적해 온 한글 데이터를 약 1TB 이상 학습했다. 이에 데이터 저작권 이슈를 최소화할 뿐 아니라 법률, 특허, 금융, 교육 등 각 전문 분야에 최적화된 맞춤형 언어모델을 빠르고 안전하게 구축할 수 있다. \n",
      "\n",
      "챗GPT 등 생성 AI의 고질적인 문제로 지적된 환각 현상을 최소화하기 위해서 ‘지식그래프(Knowledge Graph)를 활용한 사실/지식 그라운딩(Factual Grounding)’과 ‘검색 증강 생성(RAG·Retrieval-Augmented Generation)’이라는 2가지 접근법을 연계했다.\n",
      "\n",
      "솔트룩스 김재은 랩장은 자사 지식그래프와 연계하여 자체 연구·개발한 인스트럭트 지식 학습(IKL·Instruct Knowledge Learning)을 통해 오픈AI의 ‘GPT-3.5’ 및 메타의 ‘라마(Llama)2’와 대비했을 때, 한국어 할루시네이션 자체 평가에서 대략 40% 더 우수한 성능을 확인할 수 있었다고 밝혔다. \n",
      "\n",
      "출처 : 인공지능신문(https://www.aitimes.kr)\n",
      "```\n",
      "\n",
      "### Response(응답): 솔트룩스는 초거대 언어모델 LLM을 개발하고 있다. 이 언어모델은 생성 AI 시대에 적합한 모델이라고 주장한다. 솔트룩스는 이 언어모델을 통해 데이터 저작권 문제를 해결하고, 법률, 특허, 금융, 교육 등 다양한 분야에 최적화된 맞춤형 언어모델을 빠르고 안전하게 구축할 수 있다고 주장한다.</s>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'솔트룩스는 초거대 언어모델 LLM을 개발하고 있다. 이 언어모델은 생성 AI 시대에 적합한 모델이라고 주장한다. 솔트룩스는 이 언어모델을 통해 데이터 저작권 문제를 해결하고, 법률, 특허, 금융, 교육 등 다양한 분야에 최적화된 맞춤형 언어모델을 빠르고 안전하게 구축할 수 있다고 주장한다.'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen(\"\"\"\n",
    "질문 : 솔트룩스 회사의 루시아 솔루션에 대해서 설명해주세요. 솔트룩스 및 루시아에 대한 정보를 External Generated Knowledge로 드립니다.\n",
    "\n",
    "```\n",
    "인공지능 기업 솔트룩스(대표 이경일)는 ‘LUXIA Is All You Need–생성 AI 시대, 모든 것이 달라집니다'를 주제로 7일, 서울 코엑스 오디토리움에서 AI 컨퍼런스 'SAC 2023'을 개최했다.\n",
    "\n",
    "이날 행사에서는 솔트룩스가 올해 초 금융권 컨퍼런스를 통해 처음 공개한 초거대 언어모델(LLM) ‘루시아(LUXIA)’와 그 생태계가 본격적으로 소개됐다. 온오프라인 하이브리드 형태로 개최된 이번 행사의 사전 참가 신청자는 약 2,700명에 달했다.\n",
    "\n",
    "솔트룩스 이경일 대표는 키노트를 통해 도서 420만 권 분량을 학습한 자체 GPT 모델에 실시간 정보와 전문 지식을 활용해 환각 현상을 획기적으로 감소시킨 루시아GPT와 다양한 노코드 도구들을 선보였다. 또한 “처음 설립되었을 때 세상 모든 사람이 자유롭게 지식 소통하는 세상을 만들겠다는 미션을 가지고 있었던 솔트룩스는, 이제 오직 사람을 위한 인공지능 사람만을 위한 루시아GPT를 만들고 이를 통해 또 다른 성장을 시작하고자 한다”라고 말했다.  \n",
    "\n",
    "다양한 환경에 맞춤형으로 도입 가능한 똑똑한 루시아(LUXIA)\n",
    "\n",
    "루시아는 AI 데이터 구축 관련 정부 사업뿐 아니라 특허청, 행정안전부 등 다양한 분야의 사업을 수행하며 솔트룩스가 축적해 온 한글 데이터를 약 1TB 이상 학습했다. 이에 데이터 저작권 이슈를 최소화할 뿐 아니라 법률, 특허, 금융, 교육 등 각 전문 분야에 최적화된 맞춤형 언어모델을 빠르고 안전하게 구축할 수 있다. \n",
    "\n",
    "챗GPT 등 생성 AI의 고질적인 문제로 지적된 환각 현상을 최소화하기 위해서 ‘지식그래프(Knowledge Graph)를 활용한 사실/지식 그라운딩(Factual Grounding)’과 ‘검색 증강 생성(RAG·Retrieval-Augmented Generation)’이라는 2가지 접근법을 연계했다.\n",
    "\n",
    "솔트룩스 김재은 랩장은 자사 지식그래프와 연계하여 자체 연구·개발한 인스트럭트 지식 학습(IKL·Instruct Knowledge Learning)을 통해 오픈AI의 ‘GPT-3.5’ 및 메타의 ‘라마(Llama)2’와 대비했을 때, 한국어 할루시네이션 자체 평가에서 대략 40% 더 우수한 성능을 확인할 수 있었다고 밝혔다. \n",
    "\n",
    "출처 : 인공지능신문(https://www.aitimes.kr)\n",
    "```\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913bff93-1ecb-42e5-971c-77e715d8fa3f",
   "metadata": {},
   "source": [
    "* 학습되지 않아 LLM에 지식이 존재하지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7ee5fc77-9614-4aa9-8755-67d8cac81886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> 아래는 작업을 설명하는 명령어입니다.\n",
      "\b명령어를 깊게 이해하고 꼼꼼하고 차분하게 응답을 작성하세요.\n",
      "### Instruction(명령어):\n",
      "슈카월드가 뭐에요\n",
      "\n",
      "### Response(응답):슈카월드는 플랫폼 기반의 모바일 게임입니다.</s>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'슈카월드는 플랫폼 기반의 모바일 게임입니다.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen(\"\"\"\n",
    "슈카월드가 뭐에요\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "723e2e9f-1829-4c4f-9236-3e8a9b358cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> 아래는 작업을 설명하는 명령어입니다.\n",
      "\b명령어를 깊게 이해하고 꼼꼼하고 차분하게 응답을 작성하세요.\n",
      "### Instruction(명령어):\n",
      "질문 : 슈카월드가 뭐에요. 슈카월드 대한 정보를 External Generated Knowledge로 드립니다.\n",
      "슈카(본명: 전석재, 1979년~)는 대한민국의 유튜버이다. 증권 펀드매니저 출신으로, 경제 전문 1인 방송 슈카월드를 운영하고있다.\n",
      "매주 일요일 저녁, 슈카월드 유튜브 채널에서 라이브 방송을 진행한다\n",
      "\n",
      "### Response(응답):슈카월드는 경제 전문 1인 방송으로, 생산자들과 소비자들의 상호작용을 중심으로 경제 현장을 알리고 살피기 위해 만들어진 채널입니다. 슈카월드는 2015년 4월 30일에 개설되었으며, 현재 160만 명의 구독자를 보유하고 있습니다.</s>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'슈카월드는 경제 전문 1인 방송으로, 생산자들과 소비자들의 상호작용을 중심으로 경제 현장을 알리고 살피기 위해 만들어진 채널입니다. 슈카월드는 2015년 4월 30일에 개설되었으며, 현재 160만 명의 구독자를 보유하고 있습니다.'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen(\"\"\"\n",
    "질문 : 슈카월드가 뭐에요. 슈카월드 대한 정보를 External Generated Knowledge로 드립니다.\n",
    "슈카(본명: 전석재, 1979년~)는 대한민국의 유튜버이다. 증권 펀드매니저 출신으로, 경제 전문 1인 방송 슈카월드를 운영하고있다.\n",
    "매주 일요일 저녁, 슈카월드 유튜브 채널에서 라이브 방송을 진행한다\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a661ed-feba-4164-b840-52453b4a1755",
   "metadata": {},
   "source": [
    "## CoT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199abe37-d0ae-4ea4-a51e-6a3a8b871951",
   "metadata": {},
   "source": [
    "* 수학적 연산을 LLM이 제대로 하지 못함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1550b0ee-d90e-4d8c-9a19-c5506f400e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> 아래는 작업을 설명하는 명령어입니다.\n",
      "\b명령어를 깊게 이해하고 꼼꼼하고 차분하게 응답을 작성하세요.\n",
      "### Instruction(명령어):\n",
      "한 반에 30명의 학생이 있습니다. 그 중 3분의 2가 소녀입니다. 소년은 몇 명입니까?\n",
      "\n",
      "### Response(응답):15명</s>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'15명'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen(\"\"\"\n",
    "한 반에 30명의 학생이 있습니다. 그 중 3분의 2가 소녀입니다. 소년은 몇 명입니까?\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867e8a5d-3160-40bf-a303-c7f03a7f542e",
   "metadata": {},
   "source": [
    "* CoT의 Few-shot 예제를 추가하였음에도 제대로 답변을 못함\n",
    "    * KoAlpaca 데이터만 학습을 하였기에 LLM이 수학적인 사고를 하지 못함\n",
    "* 다음번에 학습시킬 때에는 CoT 데이터셋을 추가하고 실험을 해서 CoT 문제를 해결해보자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "18b7f30e-7702-482a-bfa1-2605a6925864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> 아래는 작업을 설명하는 명령어와 추가적 맥락을 제공하는 입력이 짝을 이루는 예제입니다.\n",
      "명령어와 입력을 깊게 이해하고 꼼꼼하고 차분하게 응답을 작성하세요.\n",
      "\n",
      "### Instruction(명령어):한 반에는 소년과 소녀로 이루어져 있으며, 총 60명의 학생이 있습니다. 그 중 3분의 2가 소녀입니다. 소년은 몇 명입니까? input의 예제를 보고 논리적으로 분해하고 생각을 하여 올바른 답변을 해주세요\n",
      "### Input(입력):\n",
      "예제1)\n",
      "먼저, 반 전체 학생 수인 24명 중에서 소녀의 비율을 계산해야 합니다. 소녀는 전체의 4분의 3에 해당합니다.\n",
      "24명을 4로 나누면 각 그룹에 몇 명이 있는지 알 수 있습니다. 24를 4로 나누면 6명입니다.\n",
      "이제 이 수를 3배하면 소녀의 수를 알 수 있습니다. 6명의 3배는 18명입니다. 그러므로 소녀는 18명입니다.\n",
      "전체 학생 수에서 소녀의 수를 빼면 소년의 수를 알 수 있습니다. 24명에서 18명을 빼면 6명이 남습니다.\n",
      "따라서 이 반에는 소년이 6명 있습니다.\n",
      "Response: 6명\n",
      "\n",
      "예제2)\n",
      "먼저, 반 전체 학생 수인 28명 중에서 소녀의 비율을 계산해야 합니다. 소녀는 전체의 3분의 2에 해당합니다.\n",
      "28명을 3으로 나누면 각 그룹에 몇 명이 있는지 알 수 있습니다. 28을 3으로 나누면 9.33, 즉 약 9명입니다.\n",
      "이제 이 수를 2배하면 소녀의 수를 알 수 있습니다. 9명의 2배는 18명입니다. 그러므로 소녀는 18명입니다.\n",
      "전체 학생 수에서 소녀의 수를 빼면 소년의 수를 알 수 있습니다. 28명에서 18명을 빼면 10명이 남습니다.\n",
      "따라서 이 반에는 소년이 10명 있습니다.\n",
      "Response: 10명\n",
      "\n",
      "예제3)\n",
      "먼저, 도서관 전체 책의 수인 30권 중에서 과학 책의 비율을 계산해야 합니다. 과학 책은 전체의 5분의 4에 해당합니다.\n",
      "30권을 5로 나누면 각 그룹에 몇 권이 있는지 알 수 있습니다. 30을 5로 나누면 6권입니다.\n",
      "이제 이 수를 4배하면 과학 책의 수를 알 수 있습니다. 6권의 4배는 24권입니다. 그러므로 과학 책은 24권입니다.\n",
      "전체 책의 수에서 과학 책의 수를 빼면 문학 책의 수를 알 수 있습니다. 30권에서 24권을 빼면 6권이 남습니다.\n",
      "따라서 도서관에는 문학 책이 6권 있습니다.\n",
      "Response : 6권\n",
      "\n",
      "그렇다면 instruction의 정답은??\n",
      "\n",
      "### Response(응답): 소년은 6명, 소녀는 18명입니다.</s>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'소년은 6명, 소녀는 18명입니다.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen(\n",
    "    instruction = '한 반에는 소년과 소녀로 이루어져 있으며, 총 60명의 학생이 있습니다. 그 중 3분의 2가 소녀입니다. 소년은 몇 명입니까? input의 예제를 보고 논리적으로 분해하고 생각을 하여 올바른 답변을 해주세요',\n",
    "    input=\n",
    "\"\"\"\n",
    "예제1)\n",
    "먼저, 반 전체 학생 수인 24명 중에서 소녀의 비율을 계산해야 합니다. 소녀는 전체의 4분의 3에 해당합니다.\n",
    "24명을 4로 나누면 각 그룹에 몇 명이 있는지 알 수 있습니다. 24를 4로 나누면 6명입니다.\n",
    "이제 이 수를 3배하면 소녀의 수를 알 수 있습니다. 6명의 3배는 18명입니다. 그러므로 소녀는 18명입니다.\n",
    "전체 학생 수에서 소녀의 수를 빼면 소년의 수를 알 수 있습니다. 24명에서 18명을 빼면 6명이 남습니다.\n",
    "따라서 이 반에는 소년이 6명 있습니다.\n",
    "Response: 6명\n",
    "\n",
    "예제2)\n",
    "먼저, 반 전체 학생 수인 28명 중에서 소녀의 비율을 계산해야 합니다. 소녀는 전체의 3분의 2에 해당합니다.\n",
    "28명을 3으로 나누면 각 그룹에 몇 명이 있는지 알 수 있습니다. 28을 3으로 나누면 9.33, 즉 약 9명입니다.\n",
    "이제 이 수를 2배하면 소녀의 수를 알 수 있습니다. 9명의 2배는 18명입니다. 그러므로 소녀는 18명입니다.\n",
    "전체 학생 수에서 소녀의 수를 빼면 소년의 수를 알 수 있습니다. 28명에서 18명을 빼면 10명이 남습니다.\n",
    "따라서 이 반에는 소년이 10명 있습니다.\n",
    "Response: 10명\n",
    "\n",
    "예제3)\n",
    "먼저, 도서관 전체 책의 수인 30권 중에서 과학 책의 비율을 계산해야 합니다. 과학 책은 전체의 5분의 4에 해당합니다.\n",
    "30권을 5로 나누면 각 그룹에 몇 권이 있는지 알 수 있습니다. 30을 5로 나누면 6권입니다.\n",
    "이제 이 수를 4배하면 과학 책의 수를 알 수 있습니다. 6권의 4배는 24권입니다. 그러므로 과학 책은 24권입니다.\n",
    "전체 책의 수에서 과학 책의 수를 빼면 문학 책의 수를 알 수 있습니다. 30권에서 24권을 빼면 6권이 남습니다.\n",
    "따라서 도서관에는 문학 책이 6권 있습니다.\n",
    "Response : 6권\n",
    "\n",
    "그렇다면 instruction의 정답은??\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd0229a-b80a-4162-ba33-f97c95f5ab5c",
   "metadata": {},
   "source": [
    "## 테스트 데이터셋 검증(held-out 데이터는 아님)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53c2ea45-88b6-4f8b-a211-4ec1c8bd29b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_config = GenerationConfig(\n",
    "    temperature=0.1,\n",
    "    top_k=1,\n",
    "    num_beams=3,\n",
    "    do_sample=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50ae22ff-5be7-4ec5-ae28-7bb10e66af69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2636: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1636: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아래는 작업을 설명하는 명령어입니다.\n",
      "명령어를 깊게 이해하고 꼼꼼하고 차분하게 응답을 작성하세요.\n",
      "### Instruction(명령어):고객 서비스 봇에 가장 적합한 어조를 파악하세요.\n",
      "### Response(응답):\"저희 봇은 고객 서비스를 위해 설계되었습니다. 저희 봇은 고객의 요구에 따라 적절한 대응을 할 수 있습니다.\"\n",
      "----------------------------------------------------------------------------------------------------\n",
      "아래는 작업을 설명하는 명령어입니다.\n",
      "명령어를 깊게 이해하고 꼼꼼하고 차분하게 응답을 작성하세요.\n",
      "### Instruction(명령어):동물 멸종 사건에 대한 뉴스 기사의 헤드라인을 생성합니다.\n",
      "### Response(응답):\"새로운 멸종 사건 발견\"\n",
      "----------------------------------------------------------------------------------------------------\n",
      "아래는 작업을 설명하는 명령어입니다.\n",
      "명령어를 깊게 이해하고 꼼꼼하고 차분하게 응답을 작성하세요.\n",
      "### Instruction(명령어):예산 수립을 위한 계획 만들기\n",
      "### Response(응답):예산 수립을 위한 계획을 만들기 위해서는 예산 수준과 예산 필요성을 파악하고 예산 계획을 작성해야 합니다. 이를 위해서는 예산 수준을 파악하는 방법과 예산 필요성을 파악하는 방법을 알아야 합니다. 예산 수준을 파악하는 방법은 예산 계획을 작성하는 방법과 같습니다. 예산 필요성을 파악하는 방법은 예산 계획을 작성하는 방법과 같습니다. 이를 위해서는 예산 계획을 작성하는 방법과 같은 방법을 사용해야 합니다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "아래는 작업을 설명하는 명령어입니다.\n",
      "명령어를 깊게 이해하고 꼼꼼하고 차분하게 응답을 작성하세요.\n",
      "### Instruction(명령어):\"Dear John\"이라는 표현의 어원은 무엇일까요? 왜 이별 편지나 절교장을 의미하는 표현으로 사용되는 것일까요?\n",
      "\n",
      "영어 사전에서 \"Dear\"를 검색하다 보면 여러 가지 뜻이 나오는데, 그 중에 하나가 \"Dear John (letter)\"입니다. 이 용어가 어떤 의미를 가지는 지 자세히 알고 싶습니다.\n",
      "### Response(응답):\"Dear John\"은 작가 존 디페이의 작품에서 유래된 용어입니다. 존 디페이는 1960년대 초반 미국 작가로 유명했습니다. 그는 여러 가지 작품을 남겼는데, 그 중 하나가 1963년 출간된 소설 \"The Sun is Burning\"입니다. 이 소설은 작가 자신의 이별 경험을 바탕으로 쓰여졌습니다. 이 소설에서 존 디페이는 자신의 이별 경험을 작품에 담아 출판했습니다. 이 소설에서 존 디페이는 자신의 이별 경험을 \"Dear John\"이라는 표현으로 묘사했습니다. 이 표현은 이후 미국 문학계에서 유명해졌으며, 이후 이별 편지나 절교장을 의미하는 표현으로 사용되게 되었습니다. 이 용어는 현재까지도 미국 문학계에서 사용되고 있습니다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "아래는 작업을 설명하는 명령어입니다.\n",
      "명령어를 깊게 이해하고 꼼꼼하고 차분하게 응답을 작성하세요.\n",
      "### Instruction(명령어):피보나치 수열의 처음 10개의 숫자를 출력하는 함수를 Java로 작성하십시오.\n",
      "### Response(응답):```\n",
      "public static void main(String[] args) {\n",
      "    for (int i = 0; i < 10; i++) {\n",
      "        System.out.println(fibonacci(i));\n",
      "    }\n",
      "}\n",
      "\n",
      "public static int fibonacci(int n) {\n",
      "    if (n == 0) {\n",
      "        return 0;\n",
      "    } else if (n == 1) {\n",
      "        return 1;\n",
      "    } else {\n",
      "        return fibonacci(n - 1) + fibonacci(n - 2);\n",
      "    }\n",
      "}\n",
      "```\n",
      "----------------------------------------------------------------------------------------------------\n",
      "아래는 작업을 설명하는 명령어입니다.\n",
      "명령어를 깊게 이해하고 꼼꼼하고 차분하게 응답을 작성하세요.\n",
      "### Instruction(명령어):데이터 보안을 유지할 수 있는 방법을 설명하세요.\n",
      "### Response(응답):데이터 보안을 유지하려면 다음과 같은 방법을 적용해야 합니다:\n",
      "1. 암호화 및 암호화 키 관리\n",
      "2. 적절한 액세스 제어\n",
      "3. 적절한 데이터 저장 및 처리\n",
      "4. 적절한 데이터 백업 및 복원\n",
      "5. 적절한 데이터 보호 및 보안 설비 구축\n",
      "6. 적절한 데이터 보안 관리 및 관리\n",
      "7. 적절한 데이터 보안 테스트 및 점검\n",
      "8. 적절한 데이터 보안 교육 및 훈련\n",
      "9. 적절한 데이터 보안 관리 및 관리 프로세스 구축\n",
      "10. 적절한 데이터 보안 관리 및 관리 프로세스 구축\n",
      "11. 적절한 데이터 보안 관리 및 관리 프로세스 구축\n",
      "12. 적절한 데이터 보안 관리 및 관리 프로세스 구축\n",
      "13. 적절한 데이터 보안 관\n",
      "----------------------------------------------------------------------------------------------------\n",
      "아래는 작업을 설명하는 명령어입니다.\n",
      "명령어를 깊게 이해하고 꼼꼼하고 차분하게 응답을 작성하세요.\n",
      "### Instruction(명령어):최소 5개의 규칙을 사용하여 주식 XYZ에 대한 거래 전략을 설계하세요.\n",
      "### Response(응답):주식 XYZ에 대한 거래 전략은 다음과 같습니다:\n",
      "1. 주식 XYZ가 매우 높은 가격에 달려 있을 때 주식 XYZ를 팔기로 결정합니다.\n",
      "2. 주식 XYZ가 매우 낮은 가격에 달려 있을 때 주식 XYZ를 사기로 결정합니다.\n",
      "3. 주식 XYZ가 매우 높은 가격에 달려 있을 때 주식 XYZ를 사기로 결정합니다.\n",
      "4. 주식 XYZ가 매우 낮은 가격에 달려 있을 때 주식 XYZ를 사기로 결정합니다.\n",
      "5. 주식 XYZ가 매우 높은 가격에 달려 있을 때 주식 XYZ를 사기로 결정합니다.\n",
      "6. 주식 XYZ가 매우 낮은 가격에 달려 있을 때 주식 XYZ를 사기로 결정합니다.\n",
      "7. 주식 XYZ가 매우 높은 가격에 달려 있을 때 주식 XYZ를 사기로 결정합니다.\n",
      "8. 주식 XYZ가 매우 낮은 가격에 달려 있을 �\n",
      "----------------------------------------------------------------------------------------------------\n",
      "아래는 작업을 설명하는 명령어입니다.\n",
      "명령어를 깊게 이해하고 꼼꼼하고 차분하게 응답을 작성하세요.\n",
      "### Instruction(명령어):인터넷에서 원격조정이란 게 무엇인가요? 컴퓨터를 멀리서도 원격 조정할 수 있다는데, 그게 가능한 건가요?\n",
      "### Response(응답):원격조정은 컴퓨터를 멀리서 조정하는 것입니다. 컴퓨터를 멀리서 조정하는 것은 쉽지 않은 일입니다. 컴퓨터를 멀리서 조정하는 것은 컴퓨터가 작동하는 방식에 따라 다르게 됩니다. 컴퓨터가 작동하는 방식에 따라 다르게 됩니다. 컴퓨터가 작동하는 방식에 따라 다르게 됩니다. 컴퓨터가 작동하는 방식에 따라 다르게 됩니다. 컴퓨터가 작동하는 방식에 따라 다르게 됩니다. 컴퓨터가 작동하는 방식에 따라 다르게 됩니다. 컴퓨터가 작동하는 방식에 따라 다르게 됩니다. 컴퓨터가 작동하는 방식에 따라 다르게 됩니다. 컴퓨터가 작동하는 방식에 따라 다르게 됩니다. 컴퓨터가 작동하는 방식에 따라 다르게 됩니다. 컴퓨\n",
      "----------------------------------------------------------------------------------------------------\n",
      "아래는 작업을 설명하는 명령어입니다.\n",
      "명령어를 깊게 이해하고 꼼꼼하고 차분하게 응답을 작성하세요.\n",
      "### Instruction(명령어):숨겨진 비밀 마을을 방문하기로 결정한 캐릭터에 대한 독특한 이야기를 만들어 보세요.\n",
      "### Response(응답):숨겨진 비밀 마을을 방문하기로 결정한 캐릭터에 대한 독특한 이야기를 만들어 보세요.\n",
      "숨겨진 비밀 마을을 방문하기로 결정한 캐릭터에 대한 독특한 이야기를 만들어 보세요.\n",
      "캐릭터는 숨겨진 비밀 마을을 방문하기로 결정했습니다. 그는 마을의 숨겨진 비밀을 찾기 위해 마을을 방문했습니다. 그는 마을의 숨겨진 비밀을 찾기 위해 마을을 방문했습니다. 그는 마을의 숨겨진 비밀을 찾기 위해 마을을 방문했습니다. 그는 마을의 숨겨진 비밀을 찾기 위해 마을을 방문했습니다. 그는 마을의 숨겨진 비밀을 찾기 위해 마을을 방문했습니다. 그는 마을의 숨겨진 비밀을 찾기 위해 마을을 방문했습니다. 그는 마을의 숨겨진 비밀을 찾기 위해 마을을 방문했습니다. 그는 마을의 숨겨진 비밀을 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "아래는 작업을 설명하는 명령어와 추가적 맥락을 제공하는 입력이 짝을 이루는 예제입니다.\n",
      "명령어와 입력을 깊게 이해하고 꼼꼼하고 차분하게 응답을 작성하세요.\n",
      "\n",
      "### Instruction(명령어):문장을 같은 질문을 하는 수사학적 질문으로 바꾸세요.\n",
      "### Input(입력):사과는 인기 있는 과일입니다.\n",
      "### Response(응답):사과는 어떤 과일인가요?\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['\"저희 봇은 고객 서비스를 위해 설계되었습니다. 저희 봇은 고객의 요구에 따라 적절한 대응을 할 수 있습니다.\"',\n",
       " '\"새로운 멸종 사건 발견\"',\n",
       " '예산 수립을 위한 계획을 만들기 위해서는 예산 수준과 예산 필요성을 파악하고 예산 계획을 작성해야 합니다. 이를 위해서는 예산 수준을 파악하는 방법과 예산 필요성을 파악하는 방법을 알아야 합니다. 예산 수준을 파악하는 방법은 예산 계획을 작성하는 방법과 같습니다. 예산 필요성을 파악하는 방법은 예산 계획을 작성하는 방법과 같습니다. 이를 위해서는 예산 계획을 작성하는 방법과 같은 방법을 사용해야 합니다.',\n",
       " '\"Dear John\"은 작가 존 디페이의 작품에서 유래된 용어입니다. 존 디페이는 1960년대 초반 미국 작가로 유명했습니다. 그는 여러 가지 작품을 남겼는데, 그 중 하나가 1963년 출간된 소설 \"The Sun is Burning\"입니다. 이 소설은 작가 자신의 이별 경험을 바탕으로 쓰여졌습니다. 이 소설에서 존 디페이는 자신의 이별 경험을 작품에 담아 출판했습니다. 이 소설에서 존 디페이는 자신의 이별 경험을 \"Dear John\"이라는 표현으로 묘사했습니다. 이 표현은 이후 미국 문학계에서 유명해졌으며, 이후 이별 편지나 절교장을 의미하는 표현으로 사용되게 되었습니다. 이 용어는 현재까지도 미국 문학계에서 사용되고 있습니다.',\n",
       " '```\\npublic static void main(String[] args) {\\n    for (int i = 0; i < 10; i++) {\\n        System.out.println(fibonacci(i));\\n    }\\n}\\n\\npublic static int fibonacci(int n) {\\n    if (n == 0) {\\n        return 0;\\n    } else if (n == 1) {\\n        return 1;\\n    } else {\\n        return fibonacci(n - 1) + fibonacci(n - 2);\\n    }\\n}\\n```',\n",
       " '데이터 보안을 유지하려면 다음과 같은 방법을 적용해야 합니다:\\n1. 암호화 및 암호화 키 관리\\n2. 적절한 액세스 제어\\n3. 적절한 데이터 저장 및 처리\\n4. 적절한 데이터 백업 및 복원\\n5. 적절한 데이터 보호 및 보안 설비 구축\\n6. 적절한 데이터 보안 관리 및 관리\\n7. 적절한 데이터 보안 테스트 및 점검\\n8. 적절한 데이터 보안 교육 및 훈련\\n9. 적절한 데이터 보안 관리 및 관리 프로세스 구축\\n10. 적절한 데이터 보안 관리 및 관리 프로세스 구축\\n11. 적절한 데이터 보안 관리 및 관리 프로세스 구축\\n12. 적절한 데이터 보안 관리 및 관리 프로세스 구축\\n13. 적절한 데이터 보안 관',\n",
       " '주식 XYZ에 대한 거래 전략은 다음과 같습니다:\\n1. 주식 XYZ가 매우 높은 가격에 달려 있을 때 주식 XYZ를 팔기로 결정합니다.\\n2. 주식 XYZ가 매우 낮은 가격에 달려 있을 때 주식 XYZ를 사기로 결정합니다.\\n3. 주식 XYZ가 매우 높은 가격에 달려 있을 때 주식 XYZ를 사기로 결정합니다.\\n4. 주식 XYZ가 매우 낮은 가격에 달려 있을 때 주식 XYZ를 사기로 결정합니다.\\n5. 주식 XYZ가 매우 높은 가격에 달려 있을 때 주식 XYZ를 사기로 결정합니다.\\n6. 주식 XYZ가 매우 낮은 가격에 달려 있을 때 주식 XYZ를 사기로 결정합니다.\\n7. 주식 XYZ가 매우 높은 가격에 달려 있을 때 주식 XYZ를 사기로 결정합니다.\\n8. 주식 XYZ가 매우 낮은 가격에 달려 있을 �',\n",
       " '원격조정은 컴퓨터를 멀리서 조정하는 것입니다. 컴퓨터를 멀리서 조정하는 것은 쉽지 않은 일입니다. 컴퓨터를 멀리서 조정하는 것은 컴퓨터가 작동하는 방식에 따라 다르게 됩니다. 컴퓨터가 작동하는 방식에 따라 다르게 됩니다. 컴퓨터가 작동하는 방식에 따라 다르게 됩니다. 컴퓨터가 작동하는 방식에 따라 다르게 됩니다. 컴퓨터가 작동하는 방식에 따라 다르게 됩니다. 컴퓨터가 작동하는 방식에 따라 다르게 됩니다. 컴퓨터가 작동하는 방식에 따라 다르게 됩니다. 컴퓨터가 작동하는 방식에 따라 다르게 됩니다. 컴퓨터가 작동하는 방식에 따라 다르게 됩니다. 컴퓨터가 작동하는 방식에 따라 다르게 됩니다. 컴퓨',\n",
       " '숨겨진 비밀 마을을 방문하기로 결정한 캐릭터에 대한 독특한 이야기를 만들어 보세요.\\n숨겨진 비밀 마을을 방문하기로 결정한 캐릭터에 대한 독특한 이야기를 만들어 보세요.\\n캐릭터는 숨겨진 비밀 마을을 방문하기로 결정했습니다. 그는 마을의 숨겨진 비밀을 찾기 위해 마을을 방문했습니다. 그는 마을의 숨겨진 비밀을 찾기 위해 마을을 방문했습니다. 그는 마을의 숨겨진 비밀을 찾기 위해 마을을 방문했습니다. 그는 마을의 숨겨진 비밀을 찾기 위해 마을을 방문했습니다. 그는 마을의 숨겨진 비밀을 찾기 위해 마을을 방문했습니다. 그는 마을의 숨겨진 비밀을 찾기 위해 마을을 방문했습니다. 그는 마을의 숨겨진 비밀을 찾기 위해 마을을 방문했습니다. 그는 마을의 숨겨진 비밀을',\n",
       " '사과는 어떤 과일인가요?']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_texts = []\n",
    "\n",
    "for prompt in formatted_prompts[:10]:\n",
    "    model_input = tokenizer(prompt,  padding=True, truncation=False, max_length=MAX_LENGTH, return_tensors='pt')\n",
    "\n",
    "    generated_id = model.generate(\n",
    "        **model_input,\n",
    "        max_new_tokens=MAX_LENGTH,\n",
    "        early_stopping=True,\n",
    "        generation_config=generation_config,\n",
    "        output_scores=True,\n",
    "        return_dict_in_generate=False,\n",
    "    )\n",
    "\n",
    "    generated_text = tokenizer.decode(generated_id[0], skip_special_tokens=True)\n",
    "    print(generated_text)\n",
    "    print('-' * 100)\n",
    "    generated_texts.append(generated_text)\n",
    "\n",
    "final_responses = []\n",
    "for output in generated_texts:\n",
    "    response_start_idx = output.find(\"### Response(응답):\") + len(\"### Response(응답):\")\n",
    "    response = output[response_start_idx:].strip()\n",
    "    final_responses.append(response)\n",
    "\n",
    "final_responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5580deb9-399a-4d3c-b74b-c1d4b3873a02",
   "metadata": {},
   "source": [
    "### 5.2 추론한 내용 다음 번에 재활용하기 위해 pickle 파일로 직렬화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b1c2b342-b48b-45e6-9398-b8aa57aeac09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(GENERATION_DATA_LIST_PICKLE_PATH, 'wb') as file:\n",
    "    pickle.dump(final_responses, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f087db-15ac-4182-8a6f-5d9fd8481544",
   "metadata": {},
   "source": [
    "### 5.3 저장되어져있는 추론 내용 pickle 파일로 역직렬화를 통한 메모리 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "604f2369-f0f4-4059-b527-5471fc6fd21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(GENERATION_DATA_LIST_PICKLE_PATH, 'rb') as file:\n",
    "    generation_data_list = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7683bfe7-240a-4b07-b3e2-fc69aa3da144",
   "metadata": {},
   "source": [
    "## 6. 데이터 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a00fe7e2-c6d5-4771-9c09-5882887544fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "고객 서비스에서 호칭과 제품 또는 서비스에 대한 지식을 바탕으로 열정적인 어조를 사용하는 것이 좋습니다.\n"
     ]
    }
   ],
   "source": [
    "reference_list = df_ko_alpaca_final_sampled['output'].tolist()\n",
    "print(len(reference_list))\n",
    "print(reference_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bfc0ab75-44c4-4ec5-a2be-c6ab2b834e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "import json\n",
    "\n",
    "class LLMEvaluator:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a600b1-8f1e-4b65-8863-dcbcc5813d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = LLMEvaluator()\n",
    "result = evaluator.run_evaluate(\n",
    "    predictions=generation_data_list, \n",
    "    origins=reference_list[:10],\n",
    "    use_save_as_file=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a90905a-8bc1-4b18-9fdf-9ca3f61acabc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ebc18c-ce2b-4dfb-92a5-d8173dfc57b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
